"""
è¾…åŠ©å·¥å…·å‡½æ•°
"""

import json
import logging
import logging.handlers
from functools import wraps
from typing import List, Dict, Any
from flask import request, jsonify
from datetime import datetime
import config
from .json_utils import parse_llm_json_response

# æ—¥å¿—é…ç½®æ ‡å¿—ï¼Œç¡®ä¿åªé…ç½®ä¸€æ¬¡
_logging_configured = False

def setup_logging():
    """
    é…ç½®æ—¥å¿—ç³»ç»Ÿï¼šåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
    
    åŠŸèƒ½è¯´æ˜ï¼š
    1. æ§åˆ¶å°è¾“å‡ºï¼šæ–¹ä¾¿å¼€å‘æ—¶å®æ—¶æŸ¥çœ‹æ—¥å¿—
    2. æ–‡ä»¶è¾“å‡ºï¼šä¿å­˜å†å²æ—¥å¿—ï¼Œæ–¹ä¾¿æ’æŸ¥é—®é¢˜
    3. æ—¥å¿—è½®è½¬ï¼šä½¿ç”¨ RotatingFileHandlerï¼Œé˜²æ­¢å•ä¸ªæ—¥å¿—æ–‡ä»¶è¿‡å¤§
       - æ¯ä¸ªæ—¥å¿—æ–‡ä»¶æœ€å¤§ 10MB
       - æœ€å¤šä¿ç•™ 5 ä¸ªå¤‡ä»½æ–‡ä»¶ï¼ˆæ€»è®¡çº¦ 50MBï¼‰
       - è‡ªåŠ¨æŒ‰æ—¥æœŸå‘½åï¼šbackend_YYYY-MM-DD.log
    """
    global _logging_configured
    if _logging_configured:
        return
    
    # è·å–æ ¹æ—¥å¿—è®°å½•å™¨
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    
    # æ—¥å¿—æ ¼å¼ï¼šæ—¶é—´ - æ¨¡å—å - çº§åˆ« - æ¶ˆæ¯
    log_format = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # 1. æ§åˆ¶å°å¤„ç†å™¨ï¼ˆStreamHandlerï¼‰- è¾“å‡ºåˆ°æ§åˆ¶å°
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(log_format)
    root_logger.addHandler(console_handler)
    
    # 2. æ–‡ä»¶å¤„ç†å™¨ï¼ˆRotatingFileHandlerï¼‰- ä¿å­˜åˆ°æ–‡ä»¶
    # æ—¥å¿—æ–‡ä»¶åï¼šbackend_YYYY-MM-DD.log
    log_filename = config.LOG_DIR / f"backend_{datetime.now().strftime('%Y-%m-%d')}.log"
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨ï¼ˆè·¨å¹³å°å…¼å®¹ï¼šWindows/Linux/macOSï¼‰
    try:
        config.LOG_DIR.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        # å¦‚æœç›®å½•åˆ›å»ºå¤±è´¥ï¼Œåªè¾“å‡ºåˆ°æ§åˆ¶å°
        print(f"âš ï¸ è­¦å‘Š: æ— æ³•åˆ›å»ºæ—¥å¿—ç›®å½• {config.LOG_DIR}: {e}")
        print("âš ï¸ æ—¥å¿—å°†åªè¾“å‡ºåˆ°æ§åˆ¶å°")
        _logging_configured = True
        return
    
    # ä½¿ç”¨ RotatingFileHandler å®ç°æ—¥å¿—è½®è½¬
    # maxBytes: å•ä¸ªæ–‡ä»¶æœ€å¤§ 10MB (10 * 1024 * 1024)
    # backupCount: ä¿ç•™ 5 ä¸ªå¤‡ä»½æ–‡ä»¶
    try:
        file_handler = logging.handlers.RotatingFileHandler(
            filename=str(log_filename),
            mode='a',  # è¿½åŠ æ¨¡å¼
            maxBytes=10 * 1024 * 1024,  # 10MB
            backupCount=5,  # ä¿ç•™5ä¸ªå¤‡ä»½
            encoding='utf-8'  # æ”¯æŒä¸­æ–‡
        )
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(log_format)
        root_logger.addHandler(file_handler)
        
        _logging_configured = True
        
        # è¾“å‡ºæ—¥å¿—é…ç½®ä¿¡æ¯
        logging.info("=" * 60)
        logging.info("ğŸ“ æ—¥å¿—ç³»ç»Ÿå·²é…ç½®")
        logging.info(f"   æ§åˆ¶å°è¾“å‡º: âœ… å·²å¯ç”¨")
        logging.info(f"   æ–‡ä»¶è¾“å‡º: âœ… å·²å¯ç”¨")
        logging.info(f"   æ—¥å¿—æ–‡ä»¶: {log_filename}")
        logging.info(f"   æ–‡ä»¶å¤§å°é™åˆ¶: 10MB")
        logging.info(f"   å¤‡ä»½æ–‡ä»¶æ•°: 5")
        logging.info("=" * 60)
    except Exception as e:
        # å¦‚æœæ–‡ä»¶å¤„ç†å™¨åˆ›å»ºå¤±è´¥ï¼Œåªè¾“å‡ºåˆ°æ§åˆ¶å°
        print(f"âš ï¸ è­¦å‘Š: æ— æ³•åˆ›å»ºæ—¥å¿—æ–‡ä»¶ {log_filename}: {e}")
        print("âš ï¸ æ—¥å¿—å°†åªè¾“å‡ºåˆ°æ§åˆ¶å°")
        _logging_configured = True

# åˆå§‹åŒ–æ—¥å¿—é…ç½®
setup_logging()

logger = logging.getLogger(__name__)


def get_logger(name):
    """è·å–æ—¥å¿—è®°å½•å™¨"""
    return logging.getLogger(name)


def convert_resp(code=200, status=200, message="success", data=None):
    """
    ç»Ÿä¸€å“åº”æ ¼å¼
    
    Args:
        code: ä¸šåŠ¡ä»£ç 
        status: HTTPçŠ¶æ€ç 
        message: æ¶ˆæ¯
        data: æ•°æ®
    """
    response = {
        "code": code,
        "message": message
    }
    if data is not None:
        response["data"] = data
    
    return jsonify(response), status


def auth_required(f):
    """
    è®¤è¯è£…é¥°å™¨
    """
    @wraps(f)
    def decorated_function(*args, **kwargs):
        # å¦‚æœæœªé…ç½® AUTH_TOKENï¼Œåˆ™è·³è¿‡è®¤è¯
        if not config.AUTH_TOKEN:
            return f(*args, **kwargs)
        
        # ä»è¯·æ±‚å¤´è·å– token
        auth_header = request.headers.get('Authorization')
        if not auth_header:
            return convert_resp(code=401, status=401, message="Missing authorization token")
        
        # éªŒè¯ token
        try:
            token = auth_header.replace('Bearer ', '')
            if token != config.AUTH_TOKEN:
                return convert_resp(code=401, status=401, message="Invalid token")
        except Exception as e:
            return convert_resp(code=401, status=401, message=f"Authorization failed: {str(e)}")
        
        return f(*args, **kwargs)
    
    return decorated_function


def allowed_file(filename, allowed_extensions):
    """æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦å…è®¸"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in allowed_extensions


def estimate_tokens(text: str) -> int:
    """
    ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡
    
    ç®€å•ä¼°ç®—è§„åˆ™ï¼š
    - è‹±æ–‡ï¼šçº¦ 4 ä¸ªå­—ç¬¦ = 1 token
    - ä¸­æ–‡ï¼šçº¦ 1.5 ä¸ªå­—ç¬¦ = 1 token
    - è¿™æ˜¯ä¸€ä¸ªç²—ç•¥ä¼°ç®—ï¼Œå®é™…å€¼å¯èƒ½æœ‰Â±20%çš„è¯¯å·®
    
    Args:
        text: è¦ä¼°ç®—çš„æ–‡æœ¬
    
    Returns:
        ä¼°ç®—çš„ token æ•°é‡
    """
    if not text:
        return 0
    
    # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦æ•°é‡
    chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
    # ç»Ÿè®¡å…¶ä»–å­—ç¬¦æ•°é‡
    other_chars = len(text) - chinese_chars
    
    # ä¼°ç®— tokenï¼šä¸­æ–‡æŒ‰ 1.5 å­—/tokenï¼Œè‹±æ–‡æŒ‰ 4 å­—/token
    estimated_tokens = int(chinese_chars / 1.5 + other_chars / 4)
    
    return estimated_tokens


def truncate_web_data_by_tokens(
    web_data: List[Dict[str, Any]], 
    max_tokens: int,
    content_field: str = 'content',
    use_metadata: bool = False
) -> List[Dict[str, Any]]:
    """
    æ ¹æ® token é™åˆ¶åŠ¨æ€æˆªå– web_data åˆ—è¡¨
    
    ç­–ç•¥ï¼š
    1. ä¼˜å…ˆä¿ç•™æ›´å¤šæ¡ç›®ï¼ˆé™ä½æ¯æ¡å†…å®¹é•¿åº¦ï¼‰
    2. ä¸ºæ¯æ¡æ•°æ®çš„å…ƒæ•°æ®ï¼ˆtitle, url, tags ç­‰ï¼‰é¢„ç•™ token
    3. å‰©ä½™ token å¹³å‡åˆ†é…ç»™å†…å®¹å­—æ®µ
    
    Args:
        web_data: ç½‘é¡µæ•°æ®åˆ—è¡¨
        max_tokens: æœ€å¤§å…è®¸çš„ token æ•°
        content_field: å†…å®¹å­—æ®µåç§°ï¼ˆé»˜è®¤ 'content'ï¼‰
        use_metadata: æ˜¯å¦ä½¿ç”¨ metadata æ›¿ä»£ contentï¼ˆé»˜è®¤ Falseï¼‰
    
    Returns:
        æˆªå–åçš„ç½‘é¡µæ•°æ®åˆ—è¡¨
    """
    if not web_data:
        return []
    
    logger = get_logger(__name__)
    
    # 1. ä¸ºæ¯æ¡æ•°æ®çš„å…ƒæ•°æ®é¢„ç•™ tokenï¼ˆtitleã€urlã€tags ç­‰ï¼‰
    METADATA_TOKENS_PER_ITEM = 100  # æ¯æ¡æ•°æ®çš„å…ƒæ•°æ®çº¦å  100 tokens
    
    # 2. è®¡ç®—å¯ç”¨äºå†…å®¹çš„ token æ•°
    num_items = len(web_data)
    metadata_total_tokens = num_items * METADATA_TOKENS_PER_ITEM
    
    if metadata_total_tokens >= max_tokens:
        # å¦‚æœå…ƒæ•°æ®å°±è¶…è¿‡é™åˆ¶ï¼Œå‡å°‘æ¡ç›®æ•°é‡
        max_items = max(1, max_tokens // METADATA_TOKENS_PER_ITEM)
        web_data = web_data[:max_items]
        num_items = len(web_data)
        metadata_total_tokens = num_items * METADATA_TOKENS_PER_ITEM
        logger.warning(f"Too many items, reduced to {num_items} items")
    
    content_tokens_available = max_tokens - metadata_total_tokens
    
    # 3. å¹³å‡åˆ†é…ç»™æ¯æ¡å†…å®¹
    tokens_per_content = max(50, content_tokens_available // num_items)  # æ¯æ¡å†…å®¹è‡³å°‘ 50 tokens
    
    # 4. Token è½¬æ¢ä¸ºå­—ç¬¦æ•°ï¼ˆä¿å®ˆä¼°è®¡ï¼š1 token â‰ˆ 2 å­—ç¬¦ï¼‰
    max_chars_per_content = tokens_per_content * 2
    
    if use_metadata:
        logger.info(f"Truncating {num_items} web_data items, using metadata instead of content")
    else:
        logger.info(f"Truncating {num_items} web_data items, max {max_chars_per_content} chars per content")
    
    # 5. æˆªå–æ¯æ¡æ•°æ®
    truncated_data = []
    for item in web_data:
        truncated_item = {
            "title": item.get("title", ""),
            "url": item.get("url", ""),
            "source": item.get("source", ""),
            "tags": item.get("tags", []),
            "create_time": item.get("create_time", "")
        }
        
        # å¦‚æœæœ‰ id å­—æ®µï¼Œä¿ç•™å®ƒ
        if "id" in item:
            truncated_item["id"] = item["id"]
        
        if use_metadata:
            # ä½¿ç”¨ metadata æ›¿ä»£ content
            metadata = item.get("metadata", {})
            if isinstance(metadata, dict):
                # æå– metadata ä¸­çš„æœ‰ç”¨ä¿¡æ¯
                metadata_summary = {
                    "llm_input_preview": metadata.get("llm_input_preview", ""),
                    "llm_analysis": metadata.get("llm_analysis", {}),
                    "content_type": metadata.get("content_type", ""),
                    "llm_input_mode": metadata.get("llm_input_mode", ""),
                    "diff_meta": metadata.get("diff_meta", {}) if metadata.get("change_type") == "dom-diff" else None
                }
                # ç§»é™¤ç©ºå€¼
                metadata_summary = {k: v for k, v in metadata_summary.items() if v}
                
                # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä¼°ç®—é•¿åº¦
                metadata_str = json.dumps(metadata_summary, ensure_ascii=False, indent=2)
                
                # å¦‚æœå¤ªé•¿ï¼Œæˆªå– llm_input_previewï¼ˆæœ€é•¿çš„å­—æ®µï¼‰
                if len(metadata_str) > max_chars_per_content:
                    preview = metadata_summary.get("llm_input_preview", "")
                    if preview and len(preview) > 200:
                        # æˆªå–é¢„è§ˆå†…å®¹
                        max_preview_len = max_chars_per_content - len(json.dumps({k: v for k, v in metadata_summary.items() if k != "llm_input_preview"}, ensure_ascii=False))
                        metadata_summary["llm_input_preview"] = preview[:max_preview_len] + "..."
                
                truncated_item["metadata"] = metadata_summary
            else:
                truncated_item["metadata"] = {}
        else:
            # æˆªå–å†…å®¹
            content = item.get(content_field, "")
            if isinstance(content, dict):
                content = json.dumps(content, ensure_ascii=False)
            
            if len(content) > max_chars_per_content:
                truncated_item[content_field] = content[:max_chars_per_content] + "..."
            else:
                truncated_item[content_field] = content
        
        truncated_data.append(truncated_item)
    
    return truncated_data


def calculate_available_context_tokens(
    prompt_type: str,
    additional_data_tokens: int = 0
) -> int:
    """
    è®¡ç®—å¯ç”¨äºä¸Šä¸‹æ–‡æ•°æ®çš„ token æ•°é‡
    
    Args:
        prompt_type: prompt ç±»å‹ ('tip', 'todo', 'activity', 'report')
        additional_data_tokens: é¢å¤–æ•°æ®å ç”¨çš„ tokenï¼ˆå¦‚ tipsã€todos åˆ—è¡¨ï¼‰
    
    Returns:
        å¯ç”¨äºä¸Šä¸‹æ–‡æ•°æ®çš„ token æ•°é‡
    """
    # ä»é…ç½®è·å–æ€»é™åˆ¶
    max_input_tokens = config.LLM_MAX_INPUT_TOKENS
    
    # è·å– system prompt å ç”¨çš„ token
    system_tokens = config.SYSTEM_PROMPT_TOKENS.get(prompt_type, 2000)
    
    # ç”¨æˆ·æ¶ˆæ¯ä¿ç•™çš„ token
    user_reserve_tokens = config.USER_MESSAGE_RESERVE_TOKENS
    
    # è®¡ç®—å¯ç”¨ token
    available_tokens = max_input_tokens - system_tokens - user_reserve_tokens - additional_data_tokens
    
    # ç¡®ä¿è‡³å°‘æœ‰ 500 tokens
    available_tokens = max(500, available_tokens)
    
    logger = get_logger(__name__)
    logger.info(
        f"Token allocation for '{prompt_type}': "
        f"max={max_input_tokens}, system={system_tokens}, "
        f"reserve={user_reserve_tokens}, additional={additional_data_tokens}, "
        f"available={available_tokens}"
    )
    
    return available_tokens


def parse_llm_json_response(
    text: str,
    expected_type: str = 'auto',
    extract_key: str = None,
    save_on_error: bool = False,
    error_file_prefix: str = 'failed_llm_response'
) -> Any:
    """
    ä» LLM å“åº”ä¸­æå–å’Œè§£æ JSONï¼ˆé€šç”¨å·¥å…·å‡½æ•°ï¼‰
    
    Args:
        text: LLM è¿”å›çš„åŸå§‹æ–‡æœ¬
        expected_type: æœŸæœ›çš„JSONç±»å‹ï¼Œå¯é€‰å€¼ï¼š'auto'(è‡ªåŠ¨æ£€æµ‹), 'array', 'object'
        extract_key: å¦‚æœè¿”å›çš„æ˜¯å¯¹è±¡ï¼Œä»æŒ‡å®šçš„keyä¸­æå–æ•°æ®ï¼ˆä¾‹å¦‚ï¼š'tips', 'todos'ï¼‰
        save_on_error: è§£æå¤±è´¥æ—¶æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶ä»¥ä¾¿è°ƒè¯•
        error_file_prefix: é”™è¯¯æ–‡ä»¶çš„å‰ç¼€å
    
    Returns:
        è§£æåçš„ JSON å¯¹è±¡ï¼ˆdictã€list æˆ– Noneï¼‰
    
    Examples:
        >>> parse_llm_json_response('[{"title": "test"}]', expected_type='array')
        [{"title": "test"}]
        
        >>> parse_llm_json_response('{"tips": [...]}', extract_key='tips')
        [...]
    """
    logger = get_logger(__name__)
    
    try:
        # è®°å½•åŸå§‹è¿”å›ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        logger.info(f"[JSONè§£æ] è¾“å…¥æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        logger.debug(f"[JSONè§£æ] å¼€å§‹ 500 å­—ç¬¦: {text[:500]}")
        
        # ç¬¬ä¸€æ­¥ï¼šä» markdown ä»£ç å—ä¸­æå– JSON
        json_text = _extract_json_from_markdown(text)
        
        if json_text != text:
            logger.info(f"[JSONè§£æ] ä» markdown ä»£ç å—ä¸­æå–äº† JSON")
        
        # ç¬¬äºŒæ­¥ï¼šæ¸…ç†æ–‡æœ¬
        json_text = json_text.strip()
        logger.info(f"[JSONè§£æ] æ¸…ç†åçš„ JSON é•¿åº¦: {len(json_text)} å­—ç¬¦")
        
        # ç¬¬ä¸‰æ­¥ï¼šå°è¯•è§£æ
        try:
            logger.info("[JSONè§£æ] å°è¯•ç›´æ¥è§£æ JSON...")
            parsed_data = json.loads(json_text)
            logger.info("[JSONè§£æ] âœ… ç›´æ¥è§£ææˆåŠŸ")
        except json.JSONDecodeError as e:
            logger.warning(f"[JSONè§£æ] âŒ åˆæ¬¡è§£æå¤±è´¥: {e}")
            logger.warning(f"[JSONè§£æ] é”™è¯¯ä½ç½®: line {e.lineno}, column {e.colno}")
            logger.info("[JSONè§£æ] å°è¯•ä¿®å¤ JSON æ ¼å¼é—®é¢˜...")
            # å°è¯•ä¿®å¤å¸¸è§é—®é¢˜
            json_text = _fix_json_string(json_text)
            logger.info(f"[JSONè§£æ] ä¿®å¤åçš„ JSON é•¿åº¦: {len(json_text)} å­—ç¬¦")
            parsed_data = json.loads(json_text)
            logger.info("[JSONè§£æ] âœ… ä¿®å¤åè§£ææˆåŠŸ")
        
        # ç¬¬å››æ­¥ï¼šæ ¹æ® expected_type å’Œ extract_key å¤„ç†ç»“æœ
        logger.info(f"[JSONè§£æ] åŸå§‹è§£æç»“æœç±»å‹: {type(parsed_data).__name__}")
        result = _process_parsed_data(parsed_data, expected_type, extract_key)
        
        logger.info(f"[JSONè§£æ] âœ… æœ€ç»ˆç»“æœç±»å‹: {type(result).__name__}")
        if isinstance(result, list):
            logger.info(f"[JSONè§£æ] æ•°ç»„é•¿åº¦: {len(result)}")
        elif isinstance(result, dict):
            logger.info(f"[JSONè§£æ] å¯¹è±¡é”®: {list(result.keys())}")
        
        return result
        
    except json.JSONDecodeError as e:
        logger.error("=" * 60)
        logger.error(f"[JSONè§£æ] âŒ JSON è§£æå¤±è´¥")
        logger.error(f"[JSONè§£æ] é”™è¯¯ç±»å‹: JSONDecodeError")
        logger.error(f"[JSONè§£æ] é”™è¯¯ä¿¡æ¯: {e}")
        logger.error(f"[JSONè§£æ] é”™è¯¯ä½ç½®: line {e.lineno}, column {e.colno}")
        logger.error(f"[JSONè§£æ] å¤±è´¥çš„æ–‡æœ¬ï¼ˆå‰ 1000 å­—ç¬¦ï¼‰:")
        logger.error(text[:1000])
        logger.error("=" * 60)
        
        # å¯é€‰ï¼šä¿å­˜å¤±è´¥çš„å“åº”åˆ°æ–‡ä»¶ç”¨äºè°ƒè¯•
        if save_on_error:
            _save_failed_response(text, str(e), error_file_prefix)
            logger.error(f"[JSONè§£æ] å¤±è´¥å“åº”å·²ä¿å­˜åˆ°æ–‡ä»¶: {error_file_prefix}_*.txt")
        
        return None
        
    except Exception as e:
        logger.error("=" * 60)
        logger.error(f"[JSONè§£æ] âŒ è§£æè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯")
        logger.error(f"[JSONè§£æ] é”™è¯¯ç±»å‹: {type(e).__name__}")
        logger.error(f"[JSONè§£æ] é”™è¯¯ä¿¡æ¯: {e}")
        logger.exception(f"[JSONè§£æ] å®Œæ•´å †æ ˆ:")
        logger.error("=" * 60)
        return None


def _extract_json_from_markdown(text: str) -> str:
    """
    ä» markdown ä»£ç å—ä¸­æå– JSON æ–‡æœ¬ï¼ˆæ”¹è¿›ç‰ˆï¼Œå¤„ç†åµŒå¥—ä»£ç å—ï¼‰
    
    Args:
        text: å¯èƒ½åŒ…å« markdown ä»£ç å—çš„æ–‡æœ¬
    
    Returns:
        æå–çš„ JSON æ–‡æœ¬
    """
    import re
    
    json_text = text.strip()
    
    # å¦‚æœæ–‡æœ¬ä»¥ [ æˆ– { å¼€å§‹ï¼Œä¸”ä»¥ ] æˆ– } ç»“æŸï¼Œç›´æ¥è¿”å›ï¼ˆä¸åœ¨ä»£ç å—ä¸­ï¼‰
    if (json_text.startswith('[') and json_text.endswith(']')) or \
       (json_text.startswith('{') and json_text.endswith('}')):
        return json_text
    
    # æ–¹æ³•1ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– ```json ... ``` ä»£ç å—ï¼ˆæœ€å¤–å±‚ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨éè´ªå©ªåŒ¹é…å’Œ DOTALL æ¨¡å¼æ¥æ­£ç¡®å¤„ç†åµŒå¥—çš„ä»£ç å—
    if "```json" in text:
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ª ```json æ ‡è®°
        start_marker = "```json"
        start_idx = text.find(start_marker)
        if start_idx != -1:
            # ä» ```json åå¼€å§‹æŸ¥æ‰¾å†…å®¹
            content_start = start_idx + len(start_marker)
            remaining = text[content_start:]
            
            # å¯»æ‰¾åŒ¹é…çš„ç»“æŸ ``` æ ‡è®°
            # éœ€è¦è·³è¿‡JSONå†…å®¹ä¸­çš„ä»£ç å—ï¼ˆå¦‚ ```python ... ```ï¼‰
            end_idx = _find_closing_markdown_fence(remaining)
            if end_idx != -1:
                json_text = remaining[:end_idx].strip()
                return json_text
    
    # æ–¹æ³•2ï¼šå°è¯•æå–ç¬¬ä¸€ä¸ª ``` ... ``` ä»£ç å—ï¼ˆé€šç”¨ï¼‰
    elif "```" in text:
        start_marker = "```"
        start_idx = text.find(start_marker)
        if start_idx != -1:
            content_start = start_idx + len(start_marker)
            # è·³è¿‡ç¬¬ä¸€è¡Œï¼ˆå¯èƒ½æ˜¯è¯­è¨€æ ‡è¯†ç¬¦ï¼Œå¦‚ ```pythonï¼‰
            newline_idx = text.find('\n', content_start)
            if newline_idx != -1:
                content_start = newline_idx + 1
            
            remaining = text[content_start:]
            end_idx = _find_closing_markdown_fence(remaining)
            if end_idx != -1:
                json_text = remaining[:end_idx].strip()
                return json_text
    
    # æ–¹æ³•3ï¼šå°è¯•é€šè¿‡æŸ¥æ‰¾ JSON çš„å¼€å§‹å’Œç»“æŸæ ‡è®°æ¥æå–
    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª [ æˆ– {
    start_bracket = text.find('[')
    start_brace = text.find('{')
    
    if start_bracket == -1 and start_brace == -1:
        return json_text  # æ— æ³•æ‰¾åˆ°JSONèµ·å§‹æ ‡è®°
    
    # ç¡®å®šèµ·å§‹ä½ç½®
    if start_bracket != -1 and start_brace != -1:
        start_pos = min(start_bracket, start_brace)
        is_array = start_bracket < start_brace
    elif start_bracket != -1:
        start_pos = start_bracket
        is_array = True
    else:
        start_pos = start_brace
        is_array = False
    
    # ä»èµ·å§‹ä½ç½®å¼€å§‹æå–å®Œæ•´çš„JSONç»“æ„
    extracted = _extract_complete_json(text[start_pos:], is_array)
    if extracted:
        return extracted
    
    return json_text


def _find_closing_markdown_fence(text: str) -> int:
    """
    åœ¨æ–‡æœ¬ä¸­æ‰¾åˆ°åŒ¹é…çš„markdownä»£ç å—ç»“æŸæ ‡è®°
    è¿™ä¸ªå‡½æ•°ä¼šè·³è¿‡JSONå­—ç¬¦ä¸²å†…éƒ¨çš„```æ ‡è®°
    
    Args:
        text: è¦æœç´¢çš„æ–‡æœ¬
    
    Returns:
        ç»“æŸæ ‡è®°çš„ä½ç½®ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›-1
    """
    in_string = False
    escape_next = False
    i = 0
    
    while i < len(text):
        char = text[i]
        
        # å¤„ç†è½¬ä¹‰å­—ç¬¦
        if escape_next:
            escape_next = False
            i += 1
            continue
        
        if char == '\\':
            escape_next = True
            i += 1
            continue
        
        # æ£€æµ‹æ˜¯å¦åœ¨å­—ç¬¦ä¸²å†…
        if char == '"':
            in_string = not in_string
            i += 1
            continue
        
        # å¦‚æœä¸åœ¨å­—ç¬¦ä¸²å†…ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯ä»£ç å—ç»“æŸæ ‡è®°
        if not in_string:
            if text[i:i+3] == '```':
                return i
        
        i += 1
    
    return -1


def _extract_complete_json(text: str, is_array: bool) -> str:
    """
    ä»æ–‡æœ¬ä¸­æå–å®Œæ•´çš„JSONç»“æ„
    
    Args:
        text: ä»¥JSONå¼€å§‹çš„æ–‡æœ¬
        is_array: æ˜¯å¦æ˜¯æ•°ç»„
    
    Returns:
        å®Œæ•´çš„JSONæ–‡æœ¬
    """
    if not text:
        return ""
    
    start_char = '[' if is_array else '{'
    end_char = ']' if is_array else '}'
    
    if not text.startswith(start_char):
        return ""
    
    depth = 0
    in_string = False
    escape_next = False
    
    for i, char in enumerate(text):
        if escape_next:
            escape_next = False
            continue
        
        if char == '\\':
            escape_next = True
            continue
        
        if char == '"':
            in_string = not in_string
            continue
        
        if not in_string:
            if char == start_char:
                depth += 1
            elif char == end_char:
                depth -= 1
                if depth == 0:
                    return text[:i+1]
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„ç»“æ„ï¼Œè¿”å›æ•´ä¸ªæ–‡æœ¬
    return text


def _process_parsed_data(
    parsed_data: Any,
    expected_type: str,
    extract_key: str = None
) -> Any:
    """
    æ ¹æ®æœŸæœ›çš„ç±»å‹å¤„ç†è§£æåçš„æ•°æ®
    
    Args:
        parsed_data: è§£æåçš„ JSON æ•°æ®
        expected_type: æœŸæœ›çš„ç±»å‹
        extract_key: è¦æå–çš„é”®
    
    Returns:
        å¤„ç†åçš„æ•°æ®
    """
    logger = get_logger(__name__)
    
    # å¦‚æœæŒ‡å®šäº† extract_keyï¼Œå°è¯•æå–
    if extract_key and isinstance(parsed_data, dict):
        if extract_key in parsed_data:
            parsed_data = parsed_data[extract_key]
            logger.debug(f"Extracted data from key '{extract_key}'")
        else:
            logger.warning(f"Key '{extract_key}' not found in response")
    
    # æ ¹æ® expected_type éªŒè¯å’Œè½¬æ¢
    if expected_type == 'array':
        if isinstance(parsed_data, list):
            return parsed_data
        elif isinstance(parsed_data, dict):
            # å°è¯•è‡ªåŠ¨å¯»æ‰¾æ•°ç»„
            for key in ['items', 'data', 'results', 'list']:
                if key in parsed_data and isinstance(parsed_data[key], list):
                    logger.debug(f"Auto-extracted array from key '{key}'")
                    return parsed_data[key]
            logger.warning(f"Expected array but got dict: {list(parsed_data.keys())}")
            return []
        else:
            logger.warning(f"Expected array but got {type(parsed_data)}")
            return []
    
    elif expected_type == 'object':
        if isinstance(parsed_data, dict):
            return parsed_data
        else:
            logger.warning(f"Expected object but got {type(parsed_data)}")
            return {}
    
    else:  # expected_type == 'auto'
        return parsed_data


def _fix_unescaped_quotes_in_json_strings(text: str) -> str:
    """
    ä¿®å¤JSONå­—ç¬¦ä¸²å€¼ä¸­æœªè½¬ä¹‰çš„åŒå¼•å·ï¼ˆä¸“æ³¨äºä»£ç å—ï¼‰
    
    è¿™ä¸ªå‡½æ•°ç”¨äºå¤„ç†LLMç”Ÿæˆçš„JSONä¸­ï¼Œå­—ç¬¦ä¸²å€¼åŒ…å«ä»£ç å—æ—¶ï¼Œ
    ä»£ç å—å†…çš„åŒå¼•å·æ²¡æœ‰è¢«æ­£ç¡®è½¬ä¹‰çš„æƒ…å†µã€‚
    
    ç­–ç•¥ï¼š
    1. æ‰¾åˆ°JSONå­—ç¬¦ä¸²å†…çš„æ‰€æœ‰ä»£ç å—æ ‡è®°ï¼ˆ```ï¼‰
    2. åœ¨ä»£ç å—å†…éƒ¨ï¼Œè½¬ä¹‰æ‰€æœ‰æœªè½¬ä¹‰çš„åŒå¼•å·
    
    Args:
        text: åŸå§‹JSONæ–‡æœ¬
    
    Returns:
        ä¿®å¤åçš„JSONæ–‡æœ¬
    """
    logger = get_logger(__name__)
    
    try:
        # å…ˆå°è¯•è§£æï¼Œå¦‚æœæˆåŠŸåˆ™ä¸éœ€è¦ä¿®å¤
        try:
            json.loads(text)
            return text
        except json.JSONDecodeError:
            pass
        
        logger.info("[å¼•å·ä¿®å¤] å¼€å§‹ä¿®å¤JSONå­—ç¬¦ä¸²ä¸­ä»£ç å—çš„å¼•å·...")
        
        result = []
        i = 0
        in_json_string = False
        escape_next = False
        fixes_count = 0
        
        while i < len(text):
            char = text[i]
            
            # å¤„ç†è½¬ä¹‰
            if escape_next:
                result.append(char)
                escape_next = False
                i += 1
                continue
            
            if char == '\\':
                result.append(char)
                escape_next = True
                i += 1
                continue
            
            # è·Ÿè¸ªæ˜¯å¦åœ¨JSONå­—ç¬¦ä¸²å†…
            if char == '"':
                in_json_string = not in_json_string
                result.append(char)
                i += 1
                continue
            
            # å¦‚æœåœ¨JSONå­—ç¬¦ä¸²å†…ï¼ŒæŸ¥æ‰¾ä»£ç å—
            if in_json_string and i + 2 < len(text) and text[i:i+3] == '```':
                # æ‰¾åˆ°ä»£ç å—çš„ç»“æŸ
                code_block_end = text.find('```', i + 3)
                if code_block_end != -1:
                    # å¤„ç†ä»£ç å—å†…å®¹
                    code_block_content = text[i:code_block_end+3]
                    logger.debug(f"[å¼•å·ä¿®å¤] å‘ç°ä»£ç å—ï¼Œä½ç½®: {i} - {code_block_end+3}")
                    
                    # åœ¨ä»£ç å—å†…å®¹ä¸­è½¬ä¹‰æ‰€æœ‰æœªè½¬ä¹‰çš„åŒå¼•å·
                    fixed_block = []
                    j = 0
                    block_escape_next = False
                    block_fixes = 0
                    for ch in code_block_content:
                        if block_escape_next:
                            fixed_block.append(ch)
                            block_escape_next = False
                        elif ch == '\\':
                            fixed_block.append(ch)
                            block_escape_next = True
                        elif ch == '"':
                            # åœ¨ä»£ç å—ä¸­ï¼Œè½¬ä¹‰è¿™ä¸ªå¼•å·
                            fixed_block.append('\\"')
                            block_fixes += 1
                        else:
                            fixed_block.append(ch)
                    
                    if block_fixes > 0:
                        logger.debug(f"[å¼•å·ä¿®å¤] åœ¨è¯¥ä»£ç å—ä¸­ä¿®å¤äº† {block_fixes} ä¸ªå¼•å·")
                        fixes_count += block_fixes
                    
                    result.extend(fixed_block)
                    i = code_block_end + 3
                    continue
            
            result.append(char)
            i += 1
        
        fixed_text = ''.join(result)
        
        # éªŒè¯ä¿®å¤åçš„JSON
        try:
            json.loads(fixed_text)
            logger.info(f"[å¼•å·ä¿®å¤] âœ… æˆåŠŸä¿®å¤JSONï¼Œå…±ä¿®å¤ {fixes_count} ä¸ªå¼•å·")
            return fixed_text
        except json.JSONDecodeError as e:
            logger.warning(f"[å¼•å·ä¿®å¤] âŒ ä¿®å¤åçš„JSONä»ç„¶æ— æ•ˆ: {e}")
            return text
        
    except Exception as e:
        logger.warning(f"[å¼•å·ä¿®å¤] ä¿®å¤è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        logger.exception("è¯¦ç»†å †æ ˆ:")
        return text


def _fix_latex_escapes_in_json(text: str) -> str:
    r"""
    ä¿®å¤JSONå­—ç¬¦ä¸²ä¸­çš„LaTeXè½¬ä¹‰å­—ç¬¦
    å°†æ— æ•ˆçš„LaTeXè½¬ä¹‰åºåˆ—ï¼ˆå¦‚ \[, \frac, \timesï¼‰è½¬æ¢ä¸ºæœ‰æ•ˆçš„JSONè½¬ä¹‰åºåˆ—
    
    Args:
        text: åŸå§‹JSONæ–‡æœ¬
    
    Returns:
        ä¿®å¤åçš„JSONæ–‡æœ¬
    """
    import re
    
    logger = get_logger(__name__)
    
    try:
        # ç­–ç•¥ï¼šé€ä¸ªå­—ç¬¦æ‰«æï¼Œæ™ºèƒ½å¤„ç†åæ–œæ 
        result = []
        i = 0
        while i < len(text):
            if text[i] == '\\' and i + 1 < len(text):
                next_char = text[i + 1]
                
                # åˆæ³•çš„JSONè½¬ä¹‰å­—ç¬¦
                valid_escapes = ['n', 't', 'r', '"', '\\', '/', 'b', 'f', 'u']
                
                if next_char in valid_escapes:
                    # æœ‰æ•ˆçš„è½¬ä¹‰åºåˆ—ï¼Œä¿æŒä¸å˜
                    result.append('\\')
                    result.append(next_char)
                    i += 2
                else:
                    # æ— æ•ˆçš„è½¬ä¹‰åºåˆ—ï¼ˆå¦‚\[, \fracï¼‰ï¼Œéœ€è¦è½¬ä¹‰åæ–œæ 
                    result.append('\\\\')  # æ·»åŠ é¢å¤–çš„åæ–œæ 
                    result.append(next_char)
                    i += 2
            else:
                # æ™®é€šå­—ç¬¦ï¼Œç›´æ¥æ·»åŠ 
                result.append(text[i])
                i += 1
        
        fixed_text = ''.join(result)
        logger.debug("[LaTeXä¿®å¤] å·²ä¿®å¤LaTeXè½¬ä¹‰å­—ç¬¦")
        return fixed_text
        
    except Exception as e:
        logger.warning(f"[LaTeXä¿®å¤] ä¿®å¤LaTeXè½¬ä¹‰å­—ç¬¦æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return text


def _fix_json_string(text: str) -> str:
    """
    å°è¯•ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜ï¼ˆå¢å¼ºç‰ˆï¼‰
    
    Args:
        text: åŸå§‹ JSON æ–‡æœ¬
    
    Returns:
        ä¿®å¤åçš„ JSON æ–‡æœ¬
    """
    import re
    
    logger = get_logger(__name__)
    
    try:
        original_text = text
        
        # ç¬¬ä¸€æ­¥ï¼šæ¸…ç†æ–‡æœ¬
        # ç§»é™¤å¯èƒ½çš„ BOM æ ‡è®°
        text = text.replace('\ufeff', '')
        
        # æ›¿æ¢å…¨è§’å¼•å·ä¸ºåŠè§’å¼•å·
        text = text.replace('"', '"').replace('"', '"')
        text = text.replace(''', "'").replace(''', "'")
        
        # ç§»é™¤æ§åˆ¶å­—ç¬¦ï¼ˆä¿ç•™æ¢è¡Œç¬¦ã€åˆ¶è¡¨ç¬¦å’Œå›è½¦ç¬¦ï¼‰
        text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', text)
        
        # ä¿®å¤LaTeXè½¬ä¹‰å­—ç¬¦ï¼ˆåœ¨JSONå­—ç¬¦ä¸²ä¸­æ˜¯æ— æ•ˆçš„ï¼‰
        text = _fix_latex_escapes_in_json(text)
        
        # ä¿®å¤JSONå­—ç¬¦ä¸²å€¼ä¸­æœªè½¬ä¹‰çš„åŒå¼•å·ï¼ˆç”¨äºå¤„ç†åŒ…å«ä»£ç å—ç­‰å†…å®¹çš„æƒ…å†µï¼‰
        text = _fix_unescaped_quotes_in_json_strings(text)
        
        # ç¬¬äºŒæ­¥ï¼šæ£€æµ‹JSONç»“æ„ç±»å‹
        text = text.strip()
        is_array = text.startswith('[')
        is_object = text.startswith('{')
        
        if not is_array and not is_object:
            # å°è¯•æ‰¾åˆ°JSONçš„å¼€å§‹
            start_bracket = text.find('[')
            start_brace = text.find('{')
            
            if start_bracket != -1 and start_brace != -1:
                if start_bracket < start_brace:
                    text = text[start_bracket:]
                    is_array = True
                else:
                    text = text[start_brace:]
                    is_object = True
            elif start_bracket != -1:
                text = text[start_bracket:]
                is_array = True
            elif start_brace != -1:
                text = text[start_brace:]
                is_object = True
            else:
                logger.warning("æ— æ³•æ‰¾åˆ°JSONçš„å¼€å§‹æ ‡è®°")
                return original_text
        
        # ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥å¹¶ä¿®å¤ä¸å®Œæ•´çš„JSON
        if is_array:
            # æ£€æŸ¥æ•°ç»„æ˜¯å¦æ­£ç¡®é—­åˆ
            if not text.endswith(']'):
                logger.warning("æ£€æµ‹åˆ°ä¸å®Œæ•´çš„JSONæ•°ç»„ï¼Œå°è¯•ä¿®å¤...")
                text = _fix_incomplete_array(text)
            
            # å¦‚æœä¿®å¤åä»ç„¶æ— æ•ˆï¼Œå°è¯•æå–æœ‰æ•ˆçš„å¯¹è±¡
            try:
                json.loads(text)
                return text
            except json.JSONDecodeError:
                logger.info("å°è¯•ä»ä¸å®Œæ•´çš„æ•°ç»„ä¸­æå–æœ‰æ•ˆå¯¹è±¡...")
                fixed_text = _extract_valid_objects_from_array(text)
                if fixed_text:
                    return fixed_text
        
        elif is_object:
            # æ£€æŸ¥å¯¹è±¡æ˜¯å¦æ­£ç¡®é—­åˆ
            if not text.endswith('}'):
                logger.warning("æ£€æµ‹åˆ°ä¸å®Œæ•´çš„JSONå¯¹è±¡ï¼Œå°è¯•ä¿®å¤...")
                text = _fix_incomplete_object(text)
        
        return text
        
    except Exception as e:
        logger.warning(f"ä¿®å¤JSONæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        logger.exception("è¯¦ç»†å †æ ˆ:")
        return text


def _fix_incomplete_array(text: str) -> str:
    """
    ä¿®å¤ä¸å®Œæ•´çš„JSONæ•°ç»„
    
    Args:
        text: ä¸å®Œæ•´çš„JSONæ•°ç»„æ–‡æœ¬
    
    Returns:
        ä¿®å¤åçš„JSONæ•°ç»„æ–‡æœ¬
    """
    logger = get_logger(__name__)
    
    # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å¯¹è±¡
    last_complete_brace = -1
    depth = 0
    in_string = False
    escape_next = False
    
    for i, char in enumerate(text):
        if escape_next:
            escape_next = False
            continue
        
        if char == '\\':
            escape_next = True
            continue
        
        if char == '"':
            in_string = not in_string
            continue
        
        if not in_string:
            if char == '{':
                depth += 1
            elif char == '}':
                depth -= 1
                if depth == 0:
                    last_complete_brace = i
    
    # å¦‚æœæ‰¾åˆ°äº†å®Œæ•´çš„å¯¹è±¡ï¼Œæˆªæ–­åˆ°é‚£é‡Œ
    if last_complete_brace > 0:
        truncated = text[:last_complete_brace + 1]
        # æ·»åŠ æ•°ç»„ç»“æŸç¬¦
        if not truncated.rstrip().endswith(']'):
            truncated = truncated.rstrip()
            # ç§»é™¤å¯èƒ½çš„å°¾éšé€—å·
            if truncated.endswith(','):
                truncated = truncated[:-1]
            truncated += '\n]'
        
        logger.info(f"æˆåŠŸä¿®å¤ä¸å®Œæ•´çš„JSONæ•°ç»„ï¼Œä» {len(text)} å­—ç¬¦æˆªæ–­åˆ° {len(truncated)} å­—ç¬¦")
        return truncated
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´å¯¹è±¡ï¼Œå°è¯•æ·»åŠ ç»“æŸç¬¦
    if not text.endswith(']'):
        if text.rstrip().endswith(','):
            return text.rstrip()[:-1] + ']'
        else:
            return text + ']'
    
    return text


def _fix_incomplete_object(text: str) -> str:
    """
    ä¿®å¤ä¸å®Œæ•´çš„JSONå¯¹è±¡
    
    Args:
        text: ä¸å®Œæ•´çš„JSONå¯¹è±¡æ–‡æœ¬
    
    Returns:
        ä¿®å¤åçš„JSONå¯¹è±¡æ–‡æœ¬
    """
    logger = get_logger(__name__)
    
    # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„é”®å€¼å¯¹
    depth = 0
    in_string = False
    escape_next = False
    last_complete_comma = -1
    
    for i, char in enumerate(text):
        if escape_next:
            escape_next = False
            continue
        
        if char == '\\':
            escape_next = True
            continue
        
        if char == '"':
            in_string = not in_string
            continue
        
        if not in_string:
            if char in '{[':
                depth += 1
            elif char in '}]':
                depth -= 1
            elif char == ',' and depth == 1:  # é¡¶å±‚çš„é€—å·
                last_complete_comma = i
    
    # å¦‚æœæ‰¾åˆ°äº†å®Œæ•´çš„é”®å€¼å¯¹ï¼Œæˆªæ–­åˆ°é‚£é‡Œ
    if last_complete_comma > 0:
        truncated = text[:last_complete_comma] + '\n}'
        logger.info(f"æˆåŠŸä¿®å¤ä¸å®Œæ•´çš„JSONå¯¹è±¡")
        return truncated
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ç®€å•åœ°æ·»åŠ ç»“æŸç¬¦
    if not text.endswith('}'):
        if text.rstrip().endswith(','):
            return text.rstrip()[:-1] + '}'
        else:
            return text + '}'
    
    return text


def _extract_valid_objects_from_array(text: str) -> str:
    """
    ä»å¯èƒ½ä¸å®Œæ•´çš„JSONæ•°ç»„ä¸­æå–æœ‰æ•ˆçš„å¯¹è±¡
    
    Args:
        text: JSONæ•°ç»„æ–‡æœ¬
    
    Returns:
        åŒ…å«æœ‰æ•ˆå¯¹è±¡çš„JSONæ•°ç»„æ–‡æœ¬
    """
    logger = get_logger(__name__)
    
    try:
        # æå–æ‰€æœ‰å¯èƒ½çš„å¯¹è±¡
        objects = _extract_json_objects(text)
        valid_objects = []
        
        for obj_text in objects:
            try:
                # éªŒè¯å¯¹è±¡æ˜¯å¦æœ‰æ•ˆ
                obj = json.loads(obj_text)
                valid_objects.append(obj_text)
            except json.JSONDecodeError as e:
                logger.debug(f"è·³è¿‡æ— æ•ˆå¯¹è±¡: {e}")
                # å°è¯•ä¿®å¤è¿™ä¸ªå¯¹è±¡
                try:
                    fixed_obj = _fix_incomplete_object(obj_text)
                    json.loads(fixed_obj)  # éªŒè¯ä¿®å¤åçš„å¯¹è±¡
                    valid_objects.append(fixed_obj)
                    logger.debug(f"æˆåŠŸä¿®å¤ä¸€ä¸ªå¯¹è±¡")
                except:
                    logger.debug(f"æ— æ³•ä¿®å¤å¯¹è±¡ï¼Œè·³è¿‡")
                    continue
        
        if valid_objects:
            result = '[' + ','.join(valid_objects) + ']'
            logger.info(f"ä»æ•°ç»„ä¸­æå–äº† {len(valid_objects)} ä¸ªæœ‰æ•ˆå¯¹è±¡")
            return result
        
        return None
        
    except Exception as e:
        logger.warning(f"æå–æœ‰æ•ˆå¯¹è±¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None


def _extract_json_objects(text: str) -> List[str]:
    """
    ä» JSON æ•°ç»„æ–‡æœ¬ä¸­æå–ç‹¬ç«‹çš„å¯¹è±¡
    
    Args:
        text: JSON æ•°ç»„æ–‡æœ¬
    
    Returns:
        å¯¹è±¡æ–‡æœ¬åˆ—è¡¨
    """
    objects = []
    depth = 0
    current_obj = []
    in_string = False
    escape_next = False
    
    for char in text:
        if escape_next:
            current_obj.append(char)
            escape_next = False
            continue
            
        if char == '\\':
            escape_next = True
            current_obj.append(char)
            continue
        
        if char == '"' and not escape_next:
            in_string = not in_string
            current_obj.append(char)
            continue
        
        if not in_string:
            if char == '{':
                if depth == 0:
                    current_obj = [char]
                else:
                    current_obj.append(char)
                depth += 1
            elif char == '}':
                depth -= 1
                current_obj.append(char)
                if depth == 0 and current_obj:
                    objects.append(''.join(current_obj))
                    current_obj = []
            elif depth > 0:
                current_obj.append(char)
        else:
            current_obj.append(char)
    
    return objects


def _save_failed_response(text: str, error_msg: str, prefix: str):
    """
    ä¿å­˜å¤±è´¥çš„ LLM å“åº”åˆ°æ–‡ä»¶ä»¥ä¾¿è°ƒè¯•
    
    Args:
        text: LLM å“åº”æ–‡æœ¬
        error_msg: é”™è¯¯æ¶ˆæ¯
        prefix: æ–‡ä»¶å‰ç¼€
    """
    logger = get_logger(__name__)
    
    try:
        import os
        from datetime import datetime
        
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        debug_file = os.path.join(config.DATA_DIR, f"{prefix}_{timestamp}.txt")
        
        with open(debug_file, 'w', encoding='utf-8') as f:
            f.write("=== Failed LLM Response ===\n")
            f.write(f"Timestamp: {datetime.now().isoformat()}\n")
            f.write(f"Error: {error_msg}\n")
            f.write("\n=== Full Response ===\n")
            f.write(text)
        
        logger.info(f"Failed response saved to: {debug_file}")
        
    except Exception as e:
        logger.warning(f"Could not save failed response: {e}")
