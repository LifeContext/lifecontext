"""
æ¯æ—¥Feedå¡ç‰‡ç”Ÿæˆæ¨¡å—
ç”ŸæˆåŒ…å« Summaryã€Todoã€Newsã€Knowledge ç­‰ç±»å‹çš„æ¯æ—¥æ¨èå¡ç‰‡
"""

import json
import hashlib
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from string import Template
import config
from utils.helpers import (
    get_logger,
    estimate_tokens,
    truncate_web_data_by_tokens,
    calculate_available_context_tokens
)
from utils.json_utils import parse_llm_json_response
from utils.db import get_web_data, get_todos, get_activities
from utils.llm import get_openai_client
from utils.vectorstore import search_similar_content
from utils.prompt_config import get_current_prompts
from utils.db import insert_daily_feed, get_daily_feed

logger = get_logger(__name__)

# å…¨å±€LLMå®¢æˆ·ç«¯ç¼“å­˜
_client_cache = None


def _init_llm():
    """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
    global _client_cache
    if _client_cache is None:
        _client_cache = get_openai_client()
    return _client_cache


def _generate_cover_url(card_type: str, title: str, date_str: str) -> str:
    """
    ç”Ÿæˆå°é¢å›¾ç‰‡URL
    ä½¿ç”¨å¡ç‰‡ç±»å‹+æ ‡é¢˜+æ—¥æœŸä½œä¸ºseedï¼Œç¡®ä¿åŒä¸€å¤©åŒä¸€å¡ç‰‡çš„å°é¢ä¸€è‡´
    
    Args:
        card_type: å¡ç‰‡ç±»å‹ (summary/todo/news/knowledge)
        title: å¡ç‰‡æ ‡é¢˜
        date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
    
    Returns:
        å°é¢å›¾ç‰‡URL
    """
    # ç”Ÿæˆç¨³å®šçš„seed
    seed_string = f"{card_type}_{title}_{date_str}"
    safe_seed = hashlib.md5(seed_string.encode()).hexdigest()[:16]
    
    return f"https://picsum.photos/seed/{safe_seed}/800/420"


def _assign_sequential_ids(cards: List[dict], start: int = 1) -> List[dict]:
    """ä¸º cards åˆ—è¡¨æŒ‰é¡ºåºæ·»åŠ æˆ–è¦†ç›– id å­—æ®µ
    """
    if not isinstance(cards, list):
        return cards
    for idx, card in enumerate(cards, start=start):
        try:
            if isinstance(card, dict):
                card['id'] = idx
        except Exception:
            continue
    return cards


async def generate_daily_feed(lookback_hours: int = 24) -> Dict[str, Any]:
    """
    ç”Ÿæˆæ¯æ—¥Feedå¡ç‰‡ï¼ˆä¸»å…¥å£ï¼‰
    
    Args:
        lookback_hours: å‘å‰å›æº¯çš„å°æ—¶æ•°ï¼Œé»˜è®¤24å°æ—¶
    
    Returns:
        åŒ…å«å¡ç‰‡åˆ—è¡¨çš„å­—å…¸
    """
    try:
        now = datetime.now()
        past = now - timedelta(hours=lookback_hours)
        date_str = now.strftime('%Y-%m-%d')
        
        logger.info(f"Generating daily feed for {date_str}, lookback: {lookback_hours}h")
        
        # æ”¶é›†ä¸Šä¸‹æ–‡æ•°æ®
        context = _gather_feed_context(past, now)
        
        if not context['has_content']:
            logger.warning(f"Insufficient data for daily feed generation")
            return {
                "success": False,
                "message": "insufficient data for daily feed generation"
            }
        
        # ç”Ÿæˆå„ç±»å¡ç‰‡
        cards = []
        
        # 1. ç”ŸæˆSummaryå¡ç‰‡ï¼ˆ1å¼ ï¼‰
        summary_card = await _generate_summary_card(context, date_str)
        if summary_card:
            cards.append(summary_card)
        
        # 2. ç”ŸæˆTodoå¡ç‰‡ï¼ˆ1å¼ ï¼‰
        todo_card = await _generate_todo_card(context, date_str)
        if todo_card:
            cards.append(todo_card)
        
        # 3. ç”ŸæˆNewsæ¨èå¡ç‰‡ï¼ˆ3-5å¼ ï¼‰
        news_cards = await _generate_news_cards(context, date_str, count=4)
        cards.extend(news_cards)
        
        # 4. ç”ŸæˆKnowledgeæ¨èå¡ç‰‡ï¼ˆ3-5å¼ ï¼‰
        knowledge_cards = await _generate_knowledge_cards(context, date_str, count=4)
        cards.extend(knowledge_cards)
        
        logger.info(f"Generated {len(cards)} feed cards")

        # ä¸º cards æŒ‰é¡ºåºåˆ†é… idï¼ˆä»1å¼€å§‹ï¼‰ï¼Œç„¶åä¿å­˜åˆ°æ•°æ®åº“
        try:
            cards = _assign_sequential_ids(cards, start=1)
        except Exception:
            # è‹¥å‡ºé”™åˆ™ç»§ç»­ä½¿ç”¨åŸå§‹ cards
            pass

        # å°†ç”Ÿæˆçš„Feedå­˜å‚¨åˆ°æ•°æ®åº“
        feed_id = insert_daily_feed(date_str, cards, len(cards))
        if feed_id:
            logger.info(f"Daily feed saved to database with ID {feed_id}")
        else:
            logger.warning("Failed to save daily feed to database")
        
        return {
            "success": True,
            "date": date_str,
            "cards": cards,
            "total_count": len(cards),
            "feed_id": feed_id
        }
        
    except Exception as e:
        logger.exception(f"Failed to generate daily feed: {e}")
        return {
            "success": False,
            "message": str(e)
        }


def _gather_feed_context(start_dt: datetime, end_dt: datetime) -> Dict[str, Any]:
    """æ”¶é›†Feedç”Ÿæˆæ‰€éœ€çš„ä¸Šä¸‹æ–‡æ•°æ®"""
    try:
        logger.info(f"Gathering feed context: {start_dt.strftime('%Y-%m-%d %H:%M')} to {end_dt.strftime('%Y-%m-%d %H:%M')}")
        
        context = {
            "has_content": False,
            "web_data": [],
            "activities": [],
            "todos": [],
            "start_time": start_dt.isoformat(),
            "end_time": end_dt.isoformat()
        }
        
        # è·å–ç½‘é¡µæ•°æ®
        web_data = get_web_data(
            start_time=start_dt,
            end_time=end_dt,
            limit=100
        )
        
        if web_data and len(web_data) > 0:
            context['web_data'] = web_data
            context['has_content'] = True
            logger.info(f"Found {len(web_data)} web data entries")
        
        # è·å–æ´»åŠ¨è®°å½•
        activities = get_activities(
            start_time=start_dt,
            end_time=end_dt,
            limit=50
        )
        
        if activities and len(activities) > 0:
            context['activities'] = activities
            context['has_content'] = True
            logger.info(f"Found {len(activities)} activities")
        
        # è·å–å¾…åŠäº‹é¡¹ï¼ˆæœªå®Œæˆçš„ï¼‰
        todos = get_todos(status=0, limit=20)  # status=0è¡¨ç¤ºæœªå®Œæˆ
        
        if todos and len(todos) > 0:
            context['todos'] = todos
            logger.info(f"Found {len(todos)} pending todos")
        
        return context
        
    except Exception as e:
        logger.exception(f"Error gathering feed context: {e}")
        return {
            "has_content": False,
            "web_data": [],
            "activities": [],
            "todos": []
        }


async def _generate_summary_card(context: Dict[str, Any], date_str: str) -> Optional[Dict[str, Any]]:
    """
    ç”ŸæˆSummaryæ€»ç»“å¡ç‰‡
    ä½¿ç”¨å®Œæ•´çš„reportç”Ÿæˆé€»è¾‘ï¼Œè¿”å›Markdownæ ¼å¼çš„æŠ¥å‘Š
    """
    try:
        logger.info("Generating summary card...")
        
        # å¯¼å…¥reportç”Ÿæˆå‡½æ•°
        from utils.generation.report_gen_new import create_activity_report
        from datetime import datetime
        
        # å°†æ—¶é—´èŒƒå›´è½¬æ¢ä¸ºæ—¶é—´æˆ³
        start_dt = datetime.fromisoformat(context['start_time'])
        end_dt = datetime.fromisoformat(context['end_time'])
        start_ts = int(start_dt.timestamp())
        end_ts = int(end_dt.timestamp())
        
        # ä½¿ç”¨ç°æœ‰çš„reportç”Ÿæˆé€»è¾‘
        result = await create_activity_report(start_ts, end_ts)
        
        if not result.get('success'):
            logger.warning(f"Failed to generate report: {result.get('message')}")
            return None
        
        # è·å–æŠ¥å‘Šå†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰
        report_content = result.get('content', '')
        
        if not report_content:
            logger.warning("Failed to generate summary card content")
            return None
        
        # æ„å»ºå¡ç‰‡
        card = {
            "type": "summary",
            "title": f"ä»Šæ—¥æ€»ç»“ - {date_str}",
            "content": report_content,  # Markdownæ ¼å¼çš„å®Œæ•´æŠ¥å‘Š
            "cover": _generate_cover_url("summary", "daily_summary", date_str),
            "source_url": None  # æ€»ç»“å¡ç‰‡æ²¡æœ‰ç‰¹å®šæ¥æºURL
        }
        
        logger.info("Summary card generated successfully")
        return card
        
    except Exception as e:
        logger.exception(f"Error generating summary card: {e}")
        return None


async def _generate_todo_card(context: Dict[str, Any], date_str: str) -> Optional[Dict[str, Any]]:
    """
    ç”ŸæˆTodoå¾…åŠå¡ç‰‡
    ä½¿ç”¨LLMåˆ†æå¾…åŠäº‹é¡¹ï¼Œç”Ÿæˆç»“æ„åŒ–çš„Markdownæ¸…å•
    """
    try:
        logger.info("Generating todo card...")
        
        todos = context.get('todos', [])
        
        if not todos or len(todos) == 0:
            logger.info("No pending todos, skipping todo card")
            return None
        
        client = _init_llm()
        
        # å‡†å¤‡å¾…åŠæ•°æ®JSON
        todos_json = json.dumps(todos, ensure_ascii=False, indent=2)
        
        # è·å–prompt
        todo_prompt = PROMPTS.get("todo_summary", {})
        system_prompt = todo_prompt.get("system", "")
        user_template = todo_prompt.get("user_template", "")
        
        # æ·»åŠ æ—¥å¿—æ£€æŸ¥promptæ˜¯å¦è¢«æ­£ç¡®åŠ è½½
        if system_prompt:
            logger.info(f"Using configured todo_summary prompt (length: {len(system_prompt)})")
        else:
            logger.warning("todo_summary prompt not found in PROMPTS, using fallback")
        
        # å¦‚æœæ²¡æœ‰é…ç½®promptï¼Œä½¿ç”¨é»˜è®¤çš„ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰
        if not system_prompt:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å¾…åŠäº‹é¡¹ç®¡ç†åŠ©æ‰‹ã€‚è¯·å°†å¾…åŠäº‹é¡¹æŒ‰ä¼˜å…ˆçº§æ•´ç†æˆç»“æ„åŒ–çš„Markdownæ¸…å•ã€‚

è¾“å‡ºMarkdownæ ¼å¼ï¼ŒåŒ…å«ï¼š
- æ¦‚è§ˆï¼ˆç»Ÿè®¡å’Œä¼˜å…ˆçº§åˆ†å¸ƒï¼‰
- é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆğŸ”´ï¼‰
- ä¸­ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆğŸŸ¡ï¼‰
- ä½ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆğŸŸ¢ï¼‰
- æ‰§è¡Œå»ºè®®"""
        
        if not user_template:
            user_template = """è¯·åŸºäºä»¥ä¸‹å¾…åŠäº‹é¡¹æ•°æ®ï¼Œç”Ÿæˆç»“æ„åŒ–çš„å¾…åŠä»»åŠ¡æ¸…å•ï¼š

$todos_json

ç›´æ¥è¿”å›Markdownæ ¼å¼å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»£ç å—æ ‡è®°ã€‚"""
        
        user_prompt = Template(user_template).safe_substitute(
            todos_json=todos_json
        )
        
        response = client.chat.completions.create(
            model=config.LLM_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # ç›´æ¥ä½¿ç”¨Markdownæ–‡æœ¬ä½œä¸ºå¡ç‰‡å†…å®¹
        card = {
            "type": "todo",
            "title": f"å¾…åŠä»»åŠ¡æ¸…å• ({len(todos)}é¡¹)",
            "content": result_text,
            "cover": _generate_cover_url("todo", "todo_list", date_str),
            "source_url": None  # å¾…åŠå¡ç‰‡æ²¡æœ‰ç‰¹å®šæ¥æºURL
        }
        
        logger.info("Todo card generated successfully with Markdown content")
        return card
        
    except Exception as e:
        logger.exception(f"Error generating todo card: {e}")
        return None


async def _generate_news_cards(context: Dict[str, Any], date_str: str, count: int = 4) -> List[Dict[str, Any]]:
    """
    ç”ŸæˆNewsæ–°é—»/èµ„è®¯æ¨èå¡ç‰‡
    åŸºäºç”¨æˆ·ä»Šå¤©çš„è¡Œä¸ºæ¨èç›¸å…³æ–°é—»
    æ¯æ¡æ–°é—»ç”Ÿæˆä¸€å¼ ç‹¬ç«‹çš„å¡ç‰‡
    """
    try:
        logger.info(f"Generating up to {count} news cards...")
        
        client = _init_llm()
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡æ•°æ®
        web_data = context.get('web_data', [])
        activities = context.get('activities', [])
        
        if not web_data and not activities:
            logger.info("No data for news generation")
            return []
        
        # ä¸ºnewsæ¨èé¢„ç•™è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ç©ºé—´ï¼ˆçº¦8000 tokensï¼‰
        max_context_tokens = 8000
        truncated_web_data = truncate_web_data_by_tokens(
            web_data, 
            max_tokens=max_context_tokens,
            content_field='detailed_summary',  # ä½¿ç”¨detailed_summaryå­—æ®µ
            use_metadata=False
        )
        
        logger.info(f"News generation: using {len(truncated_web_data)}/{len(web_data)} web_data items after token truncation")
        
        # æ„å»ºä¸Šä¸‹æ–‡JSON
        context_data = {
            "web_data": truncated_web_data,
            "activities": activities[:30]  # activitiesé€šå¸¸è¾ƒçŸ­ï¼Œå¯ä»¥ä¿ç•™æ›´å¤š
        }
        context_json = json.dumps(context_data, ensure_ascii=False, indent=2)
        
        # è·å–prompt
        news_prompt = PROMPTS.get("news_recommendation", {})
        system_prompt = news_prompt.get("system", "")
        user_template = news_prompt.get("user_template", "")
        
        # æ·»åŠ æ—¥å¿—æ£€æŸ¥promptæ˜¯å¦è¢«æ­£ç¡®åŠ è½½
        if system_prompt:
            logger.info(f"Using configured news_recommendation prompt (length: {len(system_prompt)})")
        else:
            logger.warning("news_recommendation prompt not found in PROMPTS, using fallback")
        
        # å¦‚æœæ²¡æœ‰é…ç½®promptï¼Œä½¿ç”¨é»˜è®¤çš„
        if not system_prompt:
            system_prompt = """ä½ æ˜¯ä¸€ä½æ™ºèƒ½æ–°é—»æ¨èåŠ©æ‰‹ã€‚åŸºäºç”¨æˆ·ä»Šå¤©çš„æµè§ˆå’Œæ´»åŠ¨æ•°æ®ï¼Œæ¨èç›¸å…³çš„æ–°é—»æˆ–èµ„è®¯ã€‚

è¿”å›JSONæ ¼å¼ï¼Œæ¯æ¡æ–°é—»åŒ…å«ï¼š
- title: æ–°é—»æ ‡é¢˜
- content: Markdownæ ¼å¼çš„æ–°é—»å†…å®¹
- source_url: æ¥æºURL
- category: åˆ†ç±»ï¼ˆé‡ç£…å‘å¸ƒ|æ·±åº¦æ´å¯Ÿ|è¡Œä¸šåŠ¨æ€ï¼‰

è¾“å‡ºæ ¼å¼ï¼š
{
  "recommendations": [
    {
      "title": "...",
      "content": "## ğŸ“Œ ...",
      "source_url": "...",
      "category": "..."
    }
  ]
}"""
        
        if not user_template:
            user_template = """è¯·åŸºäºä»¥ä¸‹ç”¨æˆ·æ•°æ®ï¼Œæ¨èç›¸å…³çš„æ–°é—»æˆ–èµ„è®¯ï¼š

$context_json

è¯·ç”Ÿæˆæ¨èåˆ—è¡¨ï¼ˆæœ€å¤š$countä¸ªï¼‰ã€‚"""
        
        user_prompt = Template(user_template).safe_substitute(
            context_json=context_json,
            count=count
        )
        
        response = client.chat.completions.create(
            model=config.LLM_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        result_text = response.choices[0].message.content.strip()
        result = parse_llm_json_response(result_text)
        
        if not result or 'recommendations' not in result:
            logger.warning("Failed to parse news recommendations")
            return []
        
        recommendations = result['recommendations']
        
        # ä¸ºæ¯æ¡æ–°é—»ç”Ÿæˆä¸€å¼ ç‹¬ç«‹çš„å¡ç‰‡
        cards = []
        for idx, rec in enumerate(recommendations[:count]):
            title = rec.get('title', '')
            content = rec.get('content', '')
            source_url = rec.get('source_url', '')
            category = rec.get('category', 'æŠ€æœ¯èµ„è®¯')
            
            if not title or not content:
                continue
            
            card = {
                "type": "news",
                "title": title,
                "content": content,  # Markdownæ ¼å¼çš„æ–°é—»å†…å®¹
                "cover": _generate_cover_url("news", title, date_str),
                "source_url": source_url
            }
            cards.append(card)
        
        logger.info(f"Generated {len(cards)} news cards")
        return cards
        
    except Exception as e:
        logger.exception(f"Error generating news cards: {e}")
        return []


async def _generate_knowledge_cards(context: Dict[str, Any], date_str: str, count: int = 4) -> List[Dict[str, Any]]:
    """
    ç”ŸæˆKnowledgeçŸ¥è¯†ç±»æ¨èå¡ç‰‡
    åŸºäºç”¨æˆ·ä»Šå¤©çš„å­¦ä¹ å’Œæ¢ç´¢æ¨èç›¸å…³çŸ¥è¯†
    æ¯æ¡çŸ¥è¯†ç”Ÿæˆä¸€å¼ ç‹¬ç«‹çš„å¡ç‰‡
    """
    try:
        logger.info(f"Generating up to {count} knowledge cards...")
        
        client = _init_llm()
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡æ•°æ®
        web_data = context.get('web_data', [])
        activities = context.get('activities', [])
        
        if not web_data and not activities:
            logger.info("No data for knowledge generation")
            return []
        
        # ä¸ºknowledgeæ¨èé¢„ç•™è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ç©ºé—´
        max_context_tokens = 10000
        truncated_web_data = truncate_web_data_by_tokens(
            web_data, 
            max_tokens=max_context_tokens,
            content_field='detailed_summary',  # ä½¿ç”¨detailed_summaryå­—æ®µ
            use_metadata=False
        )
        
        logger.info(f"Knowledge generation: using {len(truncated_web_data)}/{len(web_data)} web_data items after token truncation")
        
        # æ„å»ºä¸Šä¸‹æ–‡JSON
        context_data = {
            "web_data": truncated_web_data,
            "activities": activities[:30]  # activitiesé€šå¸¸è¾ƒçŸ­ï¼Œå¯ä»¥ä¿ç•™æ›´å¤š
        }
        context_json = json.dumps(context_data, ensure_ascii=False, indent=2)
        
        # è·å–prompt
        knowledge_prompt = PROMPTS.get("knowledge_recommendation", {})
        system_prompt = knowledge_prompt.get("system", "")
        user_template = knowledge_prompt.get("user_template", "")
        
        # æ·»åŠ æ—¥å¿—æ£€æŸ¥promptæ˜¯å¦è¢«æ­£ç¡®åŠ è½½
        if system_prompt:
            logger.info(f"Using configured knowledge_recommendation prompt (length: {len(system_prompt)})")
        else:
            logger.warning("knowledge_recommendation prompt not found in PROMPTS, using fallback")
        
        # å¦‚æœæ²¡æœ‰é…ç½®promptï¼Œä½¿ç”¨é»˜è®¤çš„ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰
        if not system_prompt:
            system_prompt = """ä½ æ˜¯ä¸€ä½æ™ºèƒ½çŸ¥è¯†æ¨èåŠ©æ‰‹ã€‚åŸºäºç”¨æˆ·ä»Šå¤©çš„å­¦ä¹ å’Œæµè§ˆæ•°æ®ï¼Œæ¨èç›¸å…³çš„çŸ¥è¯†ç±»å†…å®¹ã€‚

è¿”å›JSONæ ¼å¼ï¼Œæ¯æ¡çŸ¥è¯†åŒ…å«ï¼š
- title: çŸ¥è¯†ç‚¹æ ‡é¢˜
- content: Markdownæ ¼å¼çš„çŸ¥è¯†å†…å®¹ï¼ˆWhat-Why-How-Valueç»“æ„ï¼‰
- source_url: æ¥æºURL
- learning_value: å­¦ä¹ ä»·å€¼

è¾“å‡ºæ ¼å¼ï¼š
{
  "recommendations": [
    {
      "title": "...",
      "content": "## ğŸ“š ...",
      "source_url": "...",
      "learning_value": "..."
    }
  ]
}"""
        
        if not user_template:
            user_template = """è¯·åŸºäºä»¥ä¸‹ç”¨æˆ·æ•°æ®ï¼Œæ¨èç›¸å…³çš„çŸ¥è¯†å†…å®¹ï¼š

$context_json

è¯·ç”Ÿæˆæ¨èåˆ—è¡¨ï¼ˆæœ€å¤š$countä¸ªçŸ¥è¯†ç‚¹ï¼‰ã€‚"""
        
        user_prompt = Template(user_template).safe_substitute(
            context_json=context_json,
            count=count
        )
        
        response = client.chat.completions.create(
            model=config.LLM_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=3000
        )
        
        result_text = response.choices[0].message.content.strip()
        result = parse_llm_json_response(result_text)
        
        if not result or 'recommendations' not in result:
            logger.warning("Failed to parse knowledge recommendations")
            return []
        
        recommendations = result['recommendations']
        
        # ä¸ºæ¯æ¡çŸ¥è¯†ç”Ÿæˆä¸€å¼ ç‹¬ç«‹çš„å¡ç‰‡
        cards = []
        for idx, rec in enumerate(recommendations[:count]):
            title = rec.get('title', '')
            content = rec.get('content', '')
            source_url = rec.get('source_url', '')
            learning_value = rec.get('learning_value', '')
            
            if not title or not content:
                continue
            
            card = {
                "type": "knowledge",
                "title": title,
                "content": content,  # Markdownæ ¼å¼çš„çŸ¥è¯†å†…å®¹
                "cover": _generate_cover_url("knowledge", title, date_str),
                "source_url": source_url
            }
            cards.append(card)
        
        logger.info(f"Generated {len(cards)} knowledge cards")
        return cards
        
    except Exception as e:
        logger.exception(f"Error generating knowledge cards: {e}")
        return []
