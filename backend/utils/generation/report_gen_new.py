"""
æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆæ¨¡å—
åŸºäºæ—¶é—´èŒƒå›´å’Œç”¨æˆ·æ•°æ®ç”Ÿæˆæ´»åŠ¨åˆ†ææŠ¥å‘Š
"""

import json
from datetime import datetime
from typing import Dict, Any, List, Optional
from string import Template
import asyncio
import config
from utils.helpers import (
    get_logger,
    estimate_tokens,
    truncate_web_data_by_tokens,
    calculate_available_context_tokens
)
from utils.json_utils import parse_llm_json_response
from utils.db import get_tips, get_todos, get_web_data, get_reports, insert_report
from utils.llm import get_openai_client
from utils.vectorstore import search_similar_content
from utils.prompt_config import get_current_prompts

logger = get_logger(__name__)

_llm = None

# å…¨å±€LLMå®¢æˆ·ç«¯
_client_cache = None


def _init_llm():
    """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
    global _client_cache
    if _client_cache is None:
        _client_cache = get_openai_client()
    return _client_cache


async def create_activity_report(start_ts: int, end_ts: int) -> Dict[str, Any]:
    """
    ç”Ÿæˆæ´»åŠ¨æŠ¥å‘Šï¼ˆä¸»å…¥å£ï¼‰
    
    Args:
        start_ts: èµ·å§‹Unixæ—¶é—´æˆ³
        end_ts: ç»“æŸUnixæ—¶é—´æˆ³
    
    Returns:
        åŒ…å«æŠ¥å‘Šæ•°æ®çš„å­—å…¸
    """
    try:
        hours = (end_ts - start_ts) / 3600
        
        # æ ¹æ®æ—¶é—´è·¨åº¦é€‰æ‹©ç­–ç•¥
        if hours > 1:
            report_text = await _generate_segmented_report(start_ts, end_ts)
        else:
            report_text = await _generate_direct_report(start_ts, end_ts)
        
        if not report_text:
            return {"success": False, "message": "ç¼ºå°‘æ•°æ®æ— æ³•ç”Ÿæˆ"}
        
        # æ ¼å¼åŒ–æ—¶é—´
        dt_start = datetime.fromtimestamp(start_ts)
        dt_end = datetime.fromtimestamp(end_ts)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        title = f"æ´»åŠ¨æŠ¥å‘Š {dt_end.strftime('%Y-%m-%d %H:%M')}"
        brief = _extract_brief(report_text)
        
        rid = insert_report(
            title=title,
            content=report_text,
            summary=brief,
            document_type="activity_report"
        )
        
        logger.info(f"Report created: ID={rid}")
        
        return {
            "success": True,
            "report_id": rid,
            "content": report_text,
            "time_range": {
                "start": dt_start.isoformat(),
                "end": dt_end.isoformat()
            }
        }
    except Exception as e:
        logger.exception(f"Failed to create report: {e}")
        return {"success": False, "message": str(e)}


async def _generate_direct_report(start_ts: int, end_ts: int) -> Optional[str]:
    """ç›´æ¥ç”ŸæˆæŠ¥å‘Šï¼ˆçŸ­æ—¶é—´æ®µï¼‰"""
    data_dict = _fetch_time_range_data(start_ts, end_ts)
    
    if not data_dict.get("has_data"):
        logger.warning("No data for report")
        return None
    
    return await _ask_llm_for_report(data_dict, start_ts, end_ts)


async def _generate_segmented_report(start_ts: int, end_ts: int) -> Optional[str]:
    """åˆ†æ®µç”ŸæˆæŠ¥å‘Šï¼ˆé•¿æ—¶é—´æ®µï¼‰"""
    logger.info("Using segmented generation for long time range")
    
    # æŒ‰å°æ—¶åˆ‡åˆ†
    segments = []
    current = start_ts
    
    while current < end_ts:
        next_point = min(current + 3600, end_ts)
        segments.append((current, next_point))
        current = next_point
    
    # ç”Ÿæˆå„æ®µæ‘˜è¦
    summaries = []
    for seg_start, seg_end in segments:
        data = _fetch_time_range_data(seg_start, seg_end)
        if data:
            summary = await _make_segment_summary(data, seg_start, seg_end)
            if summary:
                summaries.append({
                    'time_start': seg_start,
                    'time_end': seg_end,
                    'text': summary
                })
    
    if not summaries:
        return None
    
    # æ±‡æ€»æˆå®Œæ•´æŠ¥å‘Š
    return await _combine_summaries(summaries, start_ts, end_ts)


def _fetch_time_range_data(start_ts: int, end_ts: int) -> Dict[str, Any]:
    """
    è·å–æ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰æ•°æ®ï¼ˆç½‘é¡µã€Tipsã€Todosï¼‰
    
    Returns:
        {
            "web_data": [...],
            "tips": [...],
            "todos": [...],
            "has_data": True/False
        }
    """
    try:
        dt_start = datetime.fromtimestamp(start_ts)
        dt_end = datetime.fromtimestamp(end_ts)
        
        logger.info(f"Fetching data: {dt_start.strftime('%Y-%m-%d %H:%M:%S')} to {dt_end.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # 1. è·å–ç½‘é¡µæ•°æ®
        raw_web_data = get_web_data(
            start_time=dt_start,
            end_time=dt_end,
            limit=100
        )
        
        web_data_list = []
        for item in raw_web_data:
            web_data_list.append({
                "id": item["id"],
                "title": item["title"],
                "url": item.get("url", ""),
                "metadata": item.get("metadata", {}),
                "source": item.get("source", "unknown"),
                "tags": item.get("tags", []),
                "create_time": item.get("create_time", "")
            })
        
        logger.info(f"Found {len(web_data_list)} web records")
        
        # 2. è·å–Tipsï¼ˆæ™ºèƒ½æç¤ºï¼‰
        tips_list = []
        try:
            all_tips = get_tips(limit=100)
            for tip in all_tips:
                tip_time_str = tip.get('create_time', '')
                if tip_time_str:
                    try:
                        tip_time = datetime.strptime(tip_time_str, '%Y-%m-%d %H:%M:%S')
                        if dt_start <= tip_time <= dt_end:
                            tips_list.append({
                                "id": tip.get("id"),
                                "title": tip.get("title", ""),
                                "content": tip.get("content", ""),
                                "type": tip.get("tip_type", "general"),
                                "create_time": tip_time_str
                            })
                    except Exception as e:
                        logger.debug(f"Failed to parse tip time: {e}")
            
            logger.info(f"Found {len(tips_list)} tips")
        except Exception as e:
            logger.warning(f"Failed to fetch tips: {e}")
        
        # 3. è·å–Todosï¼ˆå¾…åŠäº‹é¡¹ï¼‰
        todos_list = []
        try:
            all_todos = get_todos(limit=200)
            for todo in all_todos:
                todo_time_str = todo.get('create_time', '')
                if todo_time_str:
                    try:
                        todo_time = datetime.strptime(todo_time_str, '%Y-%m-%d %H:%M:%S')
                        if dt_start <= todo_time <= dt_end:
                            todos_list.append({
                                "id": todo.get("id"),
                                "title": todo.get("title", ""),
                                "description": todo.get("description", ""),
                                "status": todo.get("status", 0),  # 0=æœªå®Œæˆ, 1=å·²å®Œæˆ
                                "priority": todo.get("priority", 0),
                                "create_time": todo_time_str,
                                "end_time": todo.get("end_time", "")
                            })
                    except Exception as e:
                        logger.debug(f"Failed to parse todo time: {e}")
            
            logger.info(f"Found {len(todos_list)} todos")
        except Exception as e:
            logger.warning(f"Failed to fetch todos: {e}")
        
        # ç»„è£…ç»“æœ
        result = {
            "web_data": web_data_list,
            "tips": tips_list,
            "todos": todos_list,
            "has_data": bool(web_data_list or tips_list or todos_list)
        }
        
        if not result["has_data"]:
            # è°ƒè¯•ä¿¡æ¯
            all_records = get_web_data(limit=5)
            logger.info(f"Latest 5 web records in DB: {len(all_records)}")
            for rec in all_records:
                logger.info(f"  ID={rec['id']}, Title={rec['title']}, Time={rec.get('create_time')}")
        
        return result
    except Exception as e:
        logger.exception(f"Error fetching data: {e}")
        return {
            "web_data": [],
            "tips": [],
            "todos": [],
            "has_data": False
        }


async def _ask_llm_for_report(data_dict: Dict[str, Any], start_ts: int, end_ts: int) -> Optional[str]:
    """è°ƒç”¨LLMç”ŸæˆæŠ¥å‘Š"""
    client = _init_llm()
    
    if not client or not config.ENABLE_LLM_PROCESSING:
        logger.warning("LLM unavailable, using fallback")
        return _create_plain_report(data_dict, start_ts, end_ts)
    
    try:
        dt_start = datetime.fromtimestamp(start_ts)
        dt_end = datetime.fromtimestamp(end_ts)
        
        # é™åˆ¶æ•°æ®é‡é¿å…Tokenè¶…é™
        tips = data_dict.get("tips", [])[:20]    # æœ€å¤š20æ¡æç¤º
        todos = data_dict.get("todos", [])[:30]  # æœ€å¤š30æ¡å¾…åŠ
        
        # ä¼°ç®— tips å’Œ todos çš„ token
        other_data_json = json.dumps({
            "tips": tips,
            "todos": todos
        }, ensure_ascii=False)
        other_data_tokens = estimate_tokens(other_data_json)
        
        # è®¡ç®—å¯ç”¨äº web_data çš„ token æ•°
        available_tokens = calculate_available_context_tokens('report', other_data_tokens)
        
        # ä½¿ç”¨åŠ¨æ€æˆªå–å‡½æ•°å¤„ç† web_dataï¼Œä½¿ç”¨ metadata æ›¿ä»£ content
        web_data_trimmed = truncate_web_data_by_tokens(
            data_dict.get("web_data", []),
            max_tokens=available_tokens,
            use_metadata=True
        )
        
        report_data = {
            "web_data": web_data_trimmed,
            "tips": tips,
            "todos": todos
        }
        
        data_json = json.dumps(report_data, ensure_ascii=False, indent=2)
         
        # åŠ¨æ€è·å–å½“å‰é…ç½®çš„æç¤ºè¯
        prompts = get_current_prompts()
        sys_msg = prompts["report"]["main_system"]
        
        # å‡†å¤‡æ•°æ®é›†JSON
        web_data_json = json.dumps(report_data.get('web_data', []), ensure_ascii=False, indent=2)
        tips_json = json.dumps(report_data.get('tips', []), ensure_ascii=False, indent=2)
        todos_json = json.dumps(report_data.get('todos', []), ensure_ascii=False, indent=2)
        
        user_template = Template(prompts["report"]["main_user_template"])
        user_msg = user_template.safe_substitute(
            start_time=dt_start.strftime('%Y-%m-%d %H:%M:%S'),
            end_time=dt_end.strftime('%Y-%m-%d %H:%M:%S'),
            web_data_json=web_data_json,
            tips_json=tips_json,
            todos_json=todos_json
        )
        
        response = client.chat.completions.create(
            model=config.LLM_MODEL,
            messages=[
                {"role": "system", "content": sys_msg},
                {"role": "user", "content": user_msg}
            ],
            temperature=0.7,
            max_tokens=2500
        )
        
        result = response.choices[0].message.content
        logger.info("LLM report generated successfully")
        return result
    except Exception as e:
        logger.exception(f"LLM error: {e}")
        return _create_plain_report(data_dict, start_ts, end_ts)


async def _make_segment_summary(data_list: List[Dict], start_ts: int, end_ts: int) -> Optional[str]:
    """ç”Ÿæˆæ—¶æ®µæ‘˜è¦"""
    client = _init_llm()
    
    if not client or not config.ENABLE_LLM_PROCESSING:
        return _simple_summary(data_list)
    
    try:
        data_json = json.dumps(data_list, ensure_ascii=False, indent=2)
        dt_start = datetime.fromtimestamp(start_ts)
        dt_end = datetime.fromtimestamp(end_ts)
        
        # åŠ¨æ€è·å–å½“å‰é…ç½®çš„æç¤ºè¯
        prompts = get_current_prompts()
        system_msg = prompts["report"]["segment_system"]

        user_template = Template(prompts["report"]["segment_user_template"])
        user_msg = user_template.safe_substitute(
            start_time=dt_start.strftime('%H:%M'),
            end_time=dt_end.strftime('%H:%M'),
            data_json=data_json
        )
        
        response = client.chat.completions.create(
            model=config.LLM_MODEL,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg}
            ],
            temperature=0.5,
            max_tokens=200
        )
        
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"Summary error: {e}")
        return _simple_summary(data_list)


async def _combine_summaries(summaries: List[Dict], start_ts: int, end_ts: int) -> str:
    """åˆå¹¶æ—¶æ®µæ‘˜è¦ä¸ºå®Œæ•´æŠ¥å‘Š"""
    client = _init_llm()
    
    if not client or not config.ENABLE_LLM_PROCESSING:
        return _merge_text(summaries, start_ts, end_ts)
    
    try:
        # æ ¼å¼åŒ–æ—¶æ®µæ‘˜è¦
        summary_text = "\n\n".join([
            f"**{datetime.fromtimestamp(s['time_start']).strftime('%H:%M')} - {datetime.fromtimestamp(s['time_end']).strftime('%H:%M')}:**\n{s['text']}"
            for s in summaries
        ])
        
        dt_start = datetime.fromtimestamp(start_ts)
        dt_end = datetime.fromtimestamp(end_ts)
        
        # åŠ¨æ€è·å–å½“å‰é…ç½®çš„æç¤ºè¯
        prompts = get_current_prompts()
        system_msg = prompts["report"]["combine_system"]

        user_template = Template(prompts["report"]["combine_user_template"])
        user_msg = user_template.safe_substitute(
            start_time=dt_start.strftime('%Y-%m-%d %H:%M'),
            end_time=dt_end.strftime('%H:%M'),
            summary_text=summary_text
        )
        
        response = client.chat.completions.create(
            model=config.LLM_MODEL,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"Combine error: {e}")
        return _merge_text(summaries, start_ts, end_ts)


def _create_plain_report(data_dict: Dict[str, Any], start_ts: int, end_ts: int) -> str:
    """åˆ›å»ºç®€å•æŠ¥å‘Šï¼ˆæ— LLMï¼‰"""
    dt_start = datetime.fromtimestamp(start_ts)
    dt_end = datetime.fromtimestamp(end_ts)
    
    web_data = data_dict.get("web_data", [])
    tips = data_dict.get("tips", [])
    todos = data_dict.get("todos", [])
    
    lines = [
        f"# æ´»åŠ¨æŠ¥å‘Š",
        "",
        f"**æ—¶é—´ï¼š** {dt_start.strftime('%Y-%m-%d %H:%M')} è‡³ {dt_end.strftime('%H:%M')}",
        "",
        f"## ğŸ“Š æ¦‚è§ˆ",
        "",
        f"- ç½‘é¡µæµè§ˆï¼š{len(web_data)} æ¡",
        f"- æ™ºèƒ½æç¤ºï¼š{len(tips)} æ¡",
        f"- å¾…åŠäº‹é¡¹ï¼š{len(todos)} æ¡",
        ""
    ]
    
    # ç½‘é¡µæ´»åŠ¨åˆ—è¡¨
    if web_data:
        lines.extend([
            "## ğŸŒ ç½‘é¡µæµè§ˆæ´»åŠ¨",
            ""
        ])
        for idx, item in enumerate(web_data[:20], 1):
            lines.extend([
                f"### {idx}. {item.get('title', 'æœªå‘½å')}",
                "",
                f"- **æ¥æº:** {item.get('source', 'unknown')}",
                f"- **æ—¶é—´:** {item.get('create_time', 'unknown')}",
                f"- **é“¾æ¥:** {item.get('url', 'N/A')}",
                f"- **æ ‡ç­¾:** {', '.join(item.get('tags', []))}",
                ""
            ])
    
    # æ™ºèƒ½æç¤ºåˆ—è¡¨
    if tips:
        lines.extend([
            "## ğŸ’¡ æ™ºèƒ½æç¤º",
            ""
        ])
        for idx, tip in enumerate(tips, 1):
            lines.extend([
                f"### {idx}. {tip.get('title', 'æœªå‘½åæç¤º')}",
                "",
                f"**ç±»å‹:** {tip.get('type', 'general')}",
                "",
                tip.get('content', ''),
                "",
                f"*ç”Ÿæˆæ—¶é—´: {tip.get('create_time', 'unknown')}*",
                ""
            ])
    else:
        lines.extend([
            "## ğŸ’¡ æ™ºèƒ½æç¤º",
            "",
            "æœ¬æ—¶æ®µæœªç”Ÿæˆæ™ºèƒ½æç¤ºã€‚",
            ""
        ])
    
    # å¾…åŠäº‹é¡¹åˆ—è¡¨
    if todos:
        lines.extend([
            "## âœ… å¾…åŠäº‹é¡¹",
            ""
        ])
        completed = [t for t in todos if t.get('status') == 1]
        pending = [t for t in todos if t.get('status') == 0]
        
        lines.extend([
            f"**ç»Ÿè®¡:** å…± {len(todos)} é¡¹ï¼Œå·²å®Œæˆ {len(completed)} é¡¹ï¼Œå¾…å®Œæˆ {len(pending)} é¡¹",
            ""
        ])
        
        if pending:
            lines.extend([
                "### å¾…å®Œæˆä»»åŠ¡",
                ""
            ])
            for todo in pending:
                priority_str = "â­" * todo.get('priority', 0) if todo.get('priority', 0) > 0 else ""
                lines.extend([
                    f"- [ ] {todo.get('title', 'æœªå‘½åä»»åŠ¡')} {priority_str}",
                    f"  - {todo.get('description', '')}",
                    ""
                ])
        
        if completed:
            lines.extend([
                "### å·²å®Œæˆä»»åŠ¡",
                ""
            ])
            for todo in completed:
                lines.extend([
                    f"- [x] {todo.get('title', 'æœªå‘½åä»»åŠ¡')}",
                    f"  - {todo.get('description', '')}",
                    f"  - å®Œæˆæ—¶é—´: {todo.get('end_time', 'unknown')}",
                    ""
                ])
    else:
        lines.extend([
            "## âœ… å¾…åŠäº‹é¡¹",
            "",
            "æœ¬æ—¶æ®µæœªç”Ÿæˆå¾…åŠäº‹é¡¹ã€‚",
            ""
        ])
    
    lines.extend([
        "## ğŸ“ˆ æ€»ç»“",
        "",
        "æœ¬æŠ¥å‘ŠåŸºäºåŸå§‹æ•°æ®è‡ªåŠ¨ç”Ÿæˆã€‚",
        ""
    ])
    
    return "\n".join(lines)


def _simple_summary(data_list: List[Dict]) -> str:
    """ç”Ÿæˆç®€å•æ‘˜è¦"""
    if not data_list:
        return "æ— æ´»åŠ¨"
    
    titles = [d.get('title', 'æœªå‘½å') for d in data_list[:3]]
    text = f"å…± {len(data_list)} æ¡ï¼š" + "ã€".join(titles)
    
    if len(data_list) > 3:
        text += " ç­‰"
    
    return text


def _merge_text(summaries: List[Dict], start_ts: int, end_ts: int) -> str:
    """åˆå¹¶æ‘˜è¦æ–‡æœ¬"""
    dt_start = datetime.fromtimestamp(start_ts)
    dt_end = datetime.fromtimestamp(end_ts)
    
    lines = [
        "# æ´»åŠ¨æŠ¥å‘Š",
        "",
        f"**æ—¶é—´ï¼š** {dt_start.strftime('%Y-%m-%d %H:%M')} è‡³ {dt_end.strftime('%H:%M')}",
        "",
        "## åˆ†æ—¶æ®µæ´»åŠ¨",
        ""
    ]
    
    for seg in summaries:
        s_dt = datetime.fromtimestamp(seg['time_start'])
        e_dt = datetime.fromtimestamp(seg['time_end'])
        lines.extend([
            f"### {s_dt.strftime('%H:%M')} - {e_dt.strftime('%H:%M')}",
            "",
            seg['text'],
            ""
        ])
    
    lines.extend(["## æ€»ç»“", "", "æ±‡æ€»å„æ—¶æ®µæ´»åŠ¨ã€‚"])
    
    return "\n".join(lines)


def _extract_brief(text: str) -> str:
    """æå–ç®€è¦æ‘˜è¦"""
    lines = text.split('\n')
    non_empty = [l.strip() for l in lines if l.strip() and not l.startswith('#')]
    brief_lines = non_empty[:3]
    return ' '.join(brief_lines)[:200]
