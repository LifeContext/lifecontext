"""
LLM ç­–ç•¥æ¨¡å— - æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å’Œå·¥å…·è°ƒç”¨ç­–ç•¥
"""
import json
import asyncio
import sys
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from enum import Enum
from dataclasses import dataclass
from datetime import datetime
_backend_dir = Path(__file__).parent.parent
if str(_backend_dir) not in sys.path:
    sys.path.insert(0, str(_backend_dir))
from utils.llm import get_openai_client
from utils.helpers import get_logger
import config
from tools.base import ToolsExecutor
logger = get_logger(__name__)
@dataclass
class Intent:
    """ç”¨æˆ·æ„å›¾"""
    query: str
    type: str = "general"  # general, question, task, search, etc.
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

@dataclass
class ContextItem:
    """ä¸Šä¸‹æ–‡é¡¹"""
    id: str
    content: str
    source: str  # retrieval, entity, web_search, etc.
    metadata: Dict[str, Any] = None
    relevance_score: float = 0.0
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class ContextCollection:
    """ä¸Šä¸‹æ–‡é›†åˆ"""
    def __init__(self):
        self.items: List[ContextItem] = []
    
    def add(self, item: ContextItem):
        self.items.append(item)
    
    def get_all(self) -> List[ContextItem]:
        return self.items
    
    def get_by_source(self, source: str) -> List[ContextItem]:
        return [item for item in self.items if item.source == source]
    
    def clear(self):
        self.items.clear()


class ContextSufficiency(str, Enum):
    """ä¸Šä¸‹æ–‡å……åˆ†æ€§è¯„ä¼°ç»“æœ"""
    SUFFICIENT = "sufficient"  # è¶³å¤Ÿå›ç­”
    INSUFFICIENT = "insufficient"  # ä¸å¤Ÿï¼Œéœ€è¦æ›´å¤šå·¥å…·è°ƒç”¨
    UNKNOWN = "unknown"  # æ— æ³•ç¡®å®š



# ============================================================================
# LLMContextStrategy ä¸»ç±»
# ============================================================================

class LLMContextStrategy:
    def __init__(self):
        self.tools_executor = ToolsExecutor()
        # ä»å·¥å…·æ‰§è¡Œå™¨è·å–æ‰€æœ‰å·¥å…·å®šä¹‰
        self.all_tools = self.tools_executor.get_function_definitions()
        
        # æŒ‰ç±»åˆ«åˆ†ç±»å·¥å…·ï¼ˆå¯é€‰ï¼‰
        # åˆ é™¤ retrieval_tools åˆ†ç±»
        # self.retrieval_tools = [
        #     tool.get_function_definition() 
        #     for tool in self.tools_executor.get_all_tools()
        #     if tool.get_metadata().get("category") == "retrieval_tools"
        # ]
        
        self.profile_tools = [
            tool.get_function_definition() 
            for tool in self.tools_executor.get_all_tools()
            if tool.get_metadata().get("category") == "profile_tools"
        ]
        self.operation_tools = [
            tool.get_function_definition() 
            for tool in self.tools_executor.get_all_tools()
            if tool.get_metadata().get("category") == "operation_tools"
        ]
    
    def _get_context_summary(self, context: ContextCollection) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡æ‘˜è¦"""
        if not context.items:
            return "æš‚æ— ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚"
        
        summary_parts = []
        for item in context.items[:10]:  # æœ€å¤š10ä¸ªé¡¹
            summary_parts.append(f"- [{item.source}] {item.content[:200]}...")
        
        return "\n".join(summary_parts)
    
    def _get_detailed_context_summary(self, contexts: ContextCollection) -> str:
        """æ„å»ºè¯¦ç»†ä¸Šä¸‹æ–‡æ‘˜è¦ï¼ˆç”¨äºå……åˆ†æ€§è¯„ä¼°ï¼‰"""
        summary = f"å½“å‰ä¸Šä¸‹æ–‡åŒ…å« {len(contexts.items)} ä¸ªä¸Šä¸‹æ–‡é¡¹ï¼š\n\n"
        
        for i, item in enumerate(contexts.items, 1):
            summary += f"{i}. [æ¥æº: {item.source}] (ç›¸å…³æ€§: {item.relevance_score:.2f})\n"
            summary += f"   å†…å®¹: {item.content[:300]}...\n\n"
        
        return summary
    
    async def analyze_and_plan_tools(
        self,
        intent: Intent,
        existing_context: ContextCollection,
        iteration: int = 1
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """
        æ ¸å¿ƒåŠŸèƒ½ï¼šåˆ†æç”¨æˆ·æ„å›¾ï¼Œå†³å®šéœ€è¦è°ƒç”¨å“ªäº›å·¥å…·
        """
        try:
            client = get_openai_client()
            if not client:
                logger.error("OpenAI client not available")
                return [], {"error": "LLMæœåŠ¡ä¸å¯ç”¨"}
            
            # 1. æ„å»ºä¸Šä¸‹æ–‡æ‘˜è¦
            context_summary = self._get_context_summary(existing_context)
            
            # è°ƒè¯•ï¼šæ‰“å°å¯ç”¨å·¥å…·å’Œä¸Šä¸‹æ–‡
            logger.info(f"Available tools count: {len(self.all_tools)}")
            logger.info(f"Tool names: {[tool.get('function', {}).get('name', 'unknown') for tool in self.all_tools]}")
            logger.info(f"Existing context items: {len(existing_context.items)}")
            logger.info(f"Context summary: {context_summary[:200]}...")
            
            # 2. æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä¸Šä¸‹æ–‡åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·æ„å›¾ï¼Œå†³å®šéœ€è¦è°ƒç”¨å“ªäº›å·¥å…·æ¥è·å–æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**é‡è¦è§„åˆ™**ï¼š
1. å¦‚æœç”¨æˆ·æ˜ç¡®è¯¢é—®é‚®ä»¶/é‚®ç®±/emailç›¸å…³é—®é¢˜ï¼Œå¿…é¡»è°ƒç”¨ email_reader å·¥å…·
2. å³ä½¿å·²æœ‰ä¸€äº›æœ¬åœ°ä¸Šä¸‹æ–‡ï¼ˆå¦‚todosã€tipsï¼‰ï¼Œä¹Ÿè¦è°ƒç”¨ç›¸åº”çš„ä¸“é—¨å·¥å…·æ¥è·å–æœ€æ–°çš„é‚®ä»¶/æ—¥å†/æ–‡æ¡£ä¿¡æ¯

è¯·æ ¹æ®ç”¨æˆ·æ„å›¾å’Œå·²æœ‰ä¸Šä¸‹æ–‡ï¼Œå†³å®šéœ€è¦è°ƒç”¨å“ªäº›å·¥å…·ã€‚å¯ç”¨å·¥å…·å°†é€šè¿‡ Function Calling æä¾›ç»™ä½ ã€‚"""
            
            # 3. æ„å»ºç”¨æˆ·æç¤ºè¯
            user_prompt = f"""ç”¨æˆ·æŸ¥è¯¢: {intent.query}

å·²æœ‰ä¸Šä¸‹æ–‡:
{context_summary}

å½“å‰è¿­ä»£: {iteration}

è¯·åˆ†æè¿™ä¸ªæŸ¥è¯¢ï¼Œå†³å®šéœ€è¦è°ƒç”¨å“ªäº›å·¥å…·æ¥è·å–æ›´å¤šä¿¡æ¯ã€‚"""
            
            # 4. è°ƒç”¨ LLM (Function Calling)
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            # è°ƒè¯•ï¼šå¦‚æœæ²¡æœ‰å·¥å…·ï¼Œè®°å½•è­¦å‘Š
            if not self.all_tools:
                logger.warning("No tools available for LLM to call!")
            
            response = client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=messages,
                tools=self.all_tools if self.all_tools else None,  # å¦‚æœæ²¡æœ‰å·¥å…·ï¼Œä¼  None
                tool_choice="auto",
                temperature=0.3,
                max_tokens=config.LLM_MAX_TOKENS
            )
            
            # 5. æå–å·¥å…·è°ƒç”¨
            tool_calls = []
            analysis_message = {"content": ""}
            
            message = response.choices[0].message
            
            if message.content:
                analysis_message["content"] = message.content
                logger.debug(f"LLM analysis message: {message.content}")
            
            if message.tool_calls:
                for tool_call in message.tool_calls:
                    function_name = tool_call.function.name
                    try:
                        function_args = json.loads(tool_call.function.arguments)
                        tool_calls.append({
                            "id": tool_call.id,
                            "function_name": function_name,
                            "arguments": function_args
                        })
                        logger.info(f"Tool call planned: {function_name} with args: {function_args}")
                    except json.JSONDecodeError as e:
                        logger.error(f"Failed to parse tool call arguments: {e}")
            else:
                logger.info("LLM decided not to call any tools")
                if message.content:
                    logger.info(f"LLM reasoning: {message.content}")
            
            logger.info(f"Planned {len(tool_calls)} tool calls for iteration {iteration}")
            return tool_calls, analysis_message
            
        except Exception as e:
            logger.exception(f"Error in analyze_and_plan_tools: {e}")
            return [], {"error": str(e)}
    
    async def evaluate_sufficiency(
        self, 
        contexts: ContextCollection, 
        intent: Intent
    ) -> ContextSufficiency:
        """
        æ ¸å¿ƒåŠŸèƒ½ï¼šè¯„ä¼°å·²æœ‰ä¸Šä¸‹æ–‡æ˜¯å¦è¶³å¤Ÿå›ç­”é—®é¢˜
        
        ç‰¹åˆ«å¤„ç†ï¼šå¦‚æœç”¨æˆ·æ˜ç¡®è¯¢é—®éœ€è¦å¤–éƒ¨æ•°æ®æºçš„é—®é¢˜ï¼ˆé‚®ä»¶/æ—¥ç¨‹/æ–‡æ¡£ï¼‰ï¼Œ
        ç›´æ¥è¿”å› INSUFFICIENTï¼Œå¼ºåˆ¶è°ƒç”¨å¯¹åº”çš„å·¥å…·ã€‚
        """
        try:
            # ã€å…³é”®ä¿®å¤ã€‘æ£€æŸ¥æ˜¯å¦æ˜ç¡®éœ€è¦è°ƒç”¨ç‰¹å®šå·¥å…·
            query_lower = intent.query.lower()
            
            # å®šä¹‰éœ€è¦å¼ºåˆ¶è°ƒç”¨å·¥å…·çš„å…³é”®è¯
            email_keywords = ['é‚®ä»¶', 'é‚®ç®±', 'æ”¶ä»¶ç®±', 'email', 'mail', 'inbox', 'æœªè¯»é‚®ä»¶', 'æ–°é‚®ä»¶']
            
            # å¦‚æœåŒ…å«è¿™äº›å…³é”®è¯ï¼Œå¼ºåˆ¶è¿”å› INSUFFICIENTï¼Œè®©ç³»ç»Ÿè°ƒç”¨å·¥å…·
            if any(kw in query_lower for kw in email_keywords):
                logger.info(f"æ£€æµ‹åˆ°é‚®ä»¶ç›¸å…³å…³é”®è¯ï¼Œå¼ºåˆ¶è¿”å› INSUFFICIENT ä»¥è°ƒç”¨ email_reader")
                return ContextSufficiency.INSUFFICIENT
            
            # å¦‚æœæ²¡æœ‰ç‰¹æ®Šå…³é”®è¯ï¼ŒæŒ‰æ­£å¸¸æµç¨‹è¯„ä¼°
            client = get_openai_client()
            if not client:
                logger.warning("LLM unavailable, defaulting to INSUFFICIENT")
                return ContextSufficiency.UNKNOWN
            
            # 1. æ„å»ºè¯¦ç»†ä¸Šä¸‹æ–‡æ‘˜è¦
            context_summary = self._get_detailed_context_summary(contexts)
            
            # 2. æ„å»ºè¯„ä¼°æç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸Šä¸‹æ–‡å……åˆ†æ€§è¯„ä¼°ä¸“å®¶ã€‚è¯„ä¼°å·²æœ‰ä¸Šä¸‹æ–‡æ˜¯å¦è¶³å¤Ÿå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

è¯·è¿”å›ä»¥ä¸‹ä¸‰ç§ç»“æœä¹‹ä¸€ï¼š
- SUFFICIENT: å¦‚æœå·²æœ‰ä¸Šä¸‹æ–‡è¶³å¤Ÿå›ç­”é—®é¢˜
- INSUFFICIENT: å¦‚æœè¿˜éœ€è¦æ›´å¤šä¿¡æ¯
- UNKNOWN: å¦‚æœæ— æ³•ç¡®å®š

åªè¿”å›ç»“æœå•è¯ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""
            
            user_prompt = f"""ç”¨æˆ·æŸ¥è¯¢: {intent.query}

å·²æœ‰ä¸Šä¸‹æ–‡:
{context_summary}

è¯„ä¼°ç»“æœ:"""
            
            # 3. è°ƒç”¨ LLM
            response = client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                max_tokens=50
            )
            
            # 4. è§£æç»“æœ
            result_text = response.choices[0].message.content.strip().upper()
            
            if "SUFFICIENT" in result_text:
                return ContextSufficiency.SUFFICIENT
            elif "INSUFFICIENT" in result_text:
                return ContextSufficiency.INSUFFICIENT
            else:
                return ContextSufficiency.UNKNOWN
                
        except Exception as e:
            logger.exception(f"Error in evaluate_sufficiency: {e}")
            return ContextSufficiency.UNKNOWN
    
    async def execute_tool_calls_parallel(
        self, 
        tool_calls: List[Dict[str, Any]]
    ) -> List[ContextItem]:
        """
        æ ¸å¿ƒåŠŸèƒ½ï¼šå¹¶å‘æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œå¹¶è½¬æ¢ä¸º ContextItem
        """
        if not tool_calls:
            return []
        
        try:
            # 1. åˆ›å»ºå¼‚æ­¥ä»»åŠ¡åˆ—è¡¨
            tasks = []
            for call in tool_calls:
                function_name = call["function_name"]
                function_args = call.get("arguments", {})
                
                task = self.tools_executor.run_async(
                    function_name,
                    **function_args
                )
                tasks.append((function_name, call.get("id", ""), task))
            
            # 2. å¹¶å‘æ‰§è¡Œ
            results = await asyncio.gather(
                *[task for _, _, task in tasks],
                return_exceptions=True
            )
            
            # 3. å¤„ç†ç»“æœå¹¶è½¬æ¢
            all_items = []
            for (function_name, call_id, _), result in zip(tasks, results):
                if isinstance(result, Exception):
                    logger.error(f"Tool {function_name} failed: {result}")
                    continue
                
                context_items = self._convert_tool_result_to_context_items(
                    function_name,
                    result,
                    call_id
                )
                all_items.extend(context_items)
            
            logger.info(f"Executed {len(tool_calls)} tool calls, got {len(all_items)} context items")
            return all_items
            
        except Exception as e:
            logger.exception(f"Error in execute_tool_calls_parallel: {e}")
            return []
    
    def _convert_tool_result_to_context_items(
        self,
        function_name: str,
        result: Any,
        call_id: str = ""
    ) -> List[ContextItem]:
        """å°†å·¥å…·ç»“æœè½¬æ¢ä¸º ContextItem"""
        items = []
        
        if function_name == "web_search":
            # web_search è¿”å›çš„æ˜¯å­—å…¸æ ¼å¼ï¼ŒåŒ…å« results å­—æ®µ
            if isinstance(result, dict):
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
                if result.get("success", False):
                    search_results = result.get("results", [])
                    engine = result.get("engine", "unknown")
                    query = result.get("query", "")
                    
                    # è½¬æ¢æ¯ä¸ªæœç´¢ç»“æœ
                    for i, search_item in enumerate(search_results):
                        title = search_item.get("title", "")
                        url = search_item.get("url", "")
                        snippet = search_item.get("snippet", "")
                        
                        # æ„å»ºå†…å®¹æ‘˜è¦
                        content_text = f"æ ‡é¢˜: {title}\nURL: {url}\næ‘˜è¦: {snippet}"
                        
                        context_item = ContextItem(
                            id=f"{call_id}_search_{i}",
                            content=content_text,
                            source="web_search",
                            metadata={
                                "title": title,
                                "url": url,
                                "snippet": snippet,
                                "engine": engine,
                                "query": query
                            },
                            relevance_score=0.9  # ç½‘ç»œæœç´¢ç»“æœç›¸å…³æ€§è¾ƒé«˜
                        )
                        items.append(context_item)
                else:
                    # æœç´¢å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ä¸æ·»åŠ ä¸Šä¸‹æ–‡é¡¹
                    error_msg = result.get("error", "Unknown error")
                    logger.warning(f"Web search failed: {error_msg}")
            elif isinstance(result, list):
                # å…¼å®¹æ—§æ ¼å¼ï¼šå¦‚æœç›´æ¥è¿”å›åˆ—è¡¨ï¼ˆå¼‚å¸¸æƒ…å†µï¼‰
                logger.warning("Web search returned list format, converting...")
                for i, search_item in enumerate(result):
                    if isinstance(search_item, dict):
                        title = search_item.get("title", "")
                        url = search_item.get("url", "")
                        snippet = search_item.get("snippet", "")
                        
                        content_text = f"æ ‡é¢˜: {title}\nURL: {url}\næ‘˜è¦: {snippet}"
                        
                        context_item = ContextItem(
                            id=f"{call_id}_search_{i}",
                            content=content_text,
                            source="web_search",
                            metadata={
                                "title": title,
                                "url": url,
                                "snippet": snippet
                            },
                            relevance_score=0.9
                        )
                        items.append(context_item)
        
        elif function_name == "get_user_profile":
            # ç”¨æˆ·å¾…åŠäº‹é¡¹ã€æç¤ºä¿¡æ¯å’Œä¼šè¯è®°å¿†
            if isinstance(result, dict):
                # æ£€æŸ¥æ˜¯å¦æœ‰ context_search å­—æ®µ
                if "context_search" in result:
                    context_search = result["context_search"]
                    # ä» context_search ä¸­æå– tasksã€tipsã€memories å’Œ pages
                    tasks = context_search.get("tasks", [])
                    tips = context_search.get("tips", [])
                    memories = context_search.get("memories", [])
                    pages = context_search.get("pages", [])  # æ–°å¢ï¼šæå–pages
                    
                    # å¤„ç† tasks
                    for i, task in enumerate(tasks):
                        context_item = ContextItem(
                            id=f"{call_id}_task_{i}",
                            content=task.get("content", ""),
                            source="user_profile",
                            metadata={
                                **task.get("metadata", {}),
                                "context_type": "task"
                            },
                            relevance_score=task.get("relevance_score", 0.8)
                        )
                        items.append(context_item)
                    
                    # å¤„ç† tips
                    for i, tip in enumerate(tips):
                        context_item = ContextItem(
                            id=f"{call_id}_tip_{i}",
                            content=tip.get("content", ""),
                            source="user_profile",
                            metadata={
                                **tip.get("metadata", {}),
                                "context_type": "tip"
                            },
                            relevance_score=tip.get("relevance_score", 0.8)
                        )
                        items.append(context_item)
                    
                    # å¤„ç† memoriesï¼ˆä¼šè¯è®°å¿†ï¼‰
                    for i, memory in enumerate(memories):
                        context_item = ContextItem(
                            id=f"{call_id}_memory_{i}",
                            content=memory.get("content", ""),
                            source="session_memory",
                            metadata={
                                **memory.get("metadata", {}),
                                "context_type": memory.get("content_type", "general"),
                                "timestamp": memory.get("timestamp", "")
                            },
                            relevance_score=memory.get("relevance_score", 0.9)
                        )
                        items.append(context_item)
                    
                    # å¤„ç† pagesï¼ˆé¡µé¢å†…å®¹ï¼‰ï¼ˆæ–°å¢ï¼‰
                    for i, page in enumerate(pages):
                        metadata = page.get("metadata", {})
                        url = metadata.get("url", "")
                        source = metadata.get("source", "web_page")
                        
                        # æ ¹æ®sourceç¡®å®šæœ€ç»ˆçš„sourceæ ‡è¯†
                        if source == "chat_context":
                            final_source = "current_page"
                        elif source in ["web_crawler", "web-crawler-initial"]:
                            final_source = "web_page"
                        else:
                            final_source = "page"
                        
                        context_item = ContextItem(
                            id=f"{call_id}_page_{i}",
                            content=page.get("content", ""),
                            source=final_source,  # ä½¿ç”¨ç¡®å®šçš„source
                            metadata={
                                **metadata,
                                "context_type": "page",
                                "url": url
                            },
                            relevance_score=page.get("relevance_score", 0.9)
                        )
                        items.append(context_item)
                    
                    logger.info(f"Extracted {len(tasks)} tasks, {len(tips)} tips, {len(memories)} memories, and {len(pages)} pages from context_search")
                else:
                    # å¦‚æœæ²¡æœ‰ context_searchï¼Œå°è¯•ä»é¡¶å±‚è·å–ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                    tasks = result.get("tasks", [])
                    tips = result.get("tips", [])
                    
                    if tasks or tips:
                        logger.warning("Found tasks/tips at top level, but expected in context_search")
                        # å¤„ç†é€»è¾‘åŒä¸Š
                        for i, task in enumerate(tasks):
                            context_item = ContextItem(
                                id=f"{call_id}_task_{i}",
                                content=task.get("content", ""),
                                source="user_profile",
                                metadata={
                                    **task.get("metadata", {}),
                                    "context_type": "task"
                                },
                                relevance_score=task.get("relevance_score", 0.8)
                            )
                            items.append(context_item)
                        
                        for i, tip in enumerate(tips):
                            context_item = ContextItem(
                                id=f"{call_id}_tip_{i}",
                                content=tip.get("content", ""),
                                source="user_profile",
                                metadata={
                                    **tip.get("metadata", {}),
                                    "context_type": "tip"
                                },
                                relevance_score=tip.get("relevance_score", 0.8)
                            )
                            items.append(context_item)
        
        # å¤„ç† email_reader å·¥å…·ç»“æœ
        elif function_name == "email_reader":
            if result.get("status") == "success":
                emails = result.get("emails", [])
                for i, email in enumerate(emails):
                    email_content = f"""é‚®ä»¶ä¸»é¢˜: {email.get('subject', 'æ— ä¸»é¢˜')}
å‘ä»¶äºº: {email.get('from', 'æœªçŸ¥')}
æ”¶ä»¶äºº: {email.get('to', 'æœªçŸ¥')}
æ—¥æœŸ: {email.get('date', 'æœªçŸ¥')}
æ‘˜è¦: {email.get('snippet', 'æ— å†…å®¹')}
{'ğŸ”´ æœªè¯»' if email.get('is_unread') else ''}"""
                    
                    context_item = ContextItem(
                        id=f"{call_id}_email_{i}",
                        content=email_content,
                        source="email",
                        metadata={
                            "email_id": email.get("id", ""),
                            "subject": email.get("subject", ""),
                            "from": email.get("from", ""),
                            "date": email.get("date", ""),
                            "is_unread": email.get("is_unread", False),
                            "context_type": "email"
                        },
                        relevance_score=1.0 if email.get("is_unread") else 0.8
                    )
                    items.append(context_item)
                logger.info(f"Converted {len(emails)} emails from email_reader")
            else:
                # å¦‚æœè·å–é‚®ä»¶å¤±è´¥ï¼Œä¹Ÿè¦å‘Šè¯‰ LLM
                error_content = f"é‚®ç®±çŠ¶æ€: {result.get('status', 'unknown')}\n"
                error_content += f"ä¿¡æ¯: {result.get('message', '')}\n"
                if result.get('authorization_url'):
                    error_content += f"æˆæƒé“¾æ¥: {result.get('authorization_url')}"
                
                context_item = ContextItem(
                    id=f"{call_id}_email_status",
                    content=error_content,
                    source="email_status",
                    metadata={"status": result.get("status"), "context_type": "email_error"},
                    relevance_score=1.0
                )
                items.append(context_item)

        else:
            logger.warning(f"No conversion logic for tool: {function_name}")
            logger.warning(f"Tool result: {result}")
        logger.error(f"tool result: {result}")
        logger.error(f"items {items}")
        return items
    
    async def validate_and_filter_tool_results(
        self,
        tool_calls: List[Dict[str, Any]],
        tool_results: List[ContextItem],
        intent: Intent,
        existing_context: ContextCollection,
    ) -> Tuple[List[ContextItem], Dict[str, str]]:
        """
        æ ¸å¿ƒåŠŸèƒ½ï¼šä½¿ç”¨ LLM éªŒè¯å·¥å…·ç»“æœçš„ç›¸å…³æ€§ï¼Œè¿‡æ»¤ä½ç›¸å…³æ€§é¡¹
        """
        if not tool_results:
            return [], {"message": "æ²¡æœ‰å·¥å…·ç»“æœéœ€è¦éªŒè¯"}
        
        # ä¸´æ—¶è°ƒè¯•ï¼šå¦‚æœç»“æœæ•°é‡å¾ˆå°‘ï¼ˆ<=5ï¼‰ï¼Œç›´æ¥è¿”å›æ‰€æœ‰ç»“æœ
        if len(tool_results) <= 5:
            logger.info(f"Tool results count ({len(tool_results)}) is small, skipping validation")
            return tool_results, {"message": "ç»“æœæ•°é‡è¾ƒå°‘ï¼Œè·³è¿‡éªŒè¯"}
        
        try:
            client = get_openai_client()
            if not client:
                logger.warning("LLM unavailable, returning all results")
                return tool_results, {"message": "éªŒè¯æœåŠ¡ä¸å¯ç”¨ï¼Œè¿”å›æ‰€æœ‰ç»“æœ"}
            
            # 1. æ„å»ºç»“æœæ‘˜è¦
            results_summary = []
            for item in tool_results:
                results_summary.append({
                    "result_id": item.id,
                    "content": item.content[:500],  # é™åˆ¶é•¿åº¦
                    "source": item.source,
                    "relevance_score": item.relevance_score
                })
            
            # 2. æ„å»ºéªŒè¯æç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸Šä¸‹æ–‡ç›¸å…³æ€§éªŒè¯ä¸“å®¶ã€‚è¯„ä¼°å·¥å…·ç»“æœä¸ç”¨æˆ·æŸ¥è¯¢çš„ç›¸å…³æ€§ã€‚

è¯·è¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- relevant_result_ids: ç›¸å…³ç»“æœIDåˆ—è¡¨
- validation_message: éªŒè¯è¯´æ˜

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""
            
            user_prompt = f"""ç”¨æˆ·æŸ¥è¯¢: {intent.query}

å·¥å…·ç»“æœåˆ—è¡¨:
{json.dumps(results_summary, ensure_ascii=False, indent=2)}

è¯·è¯„ä¼°æ¯ä¸ªç»“æœçš„ç›¸å…³æ€§ï¼Œè¿”å›ç›¸å…³ç»“æœIDåˆ—è¡¨ã€‚"""
            
            # 3. è°ƒç”¨ LLM éªŒè¯
            response = client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                max_tokens=500,
                response_format={"type": "json_object"}
            )
            
            # 4. è§£æéªŒè¯ç»“æœ
            validation_json = json.loads(response.choices[0].message.content)
            relevant_ids = set(validation_json.get("relevant_result_ids", []))
            validation_message = validation_json.get("validation_message", "")
            
            # 5. è¿‡æ»¤ç›¸å…³é¡¹
            relevant_items = [
                item for item in tool_results 
                if item.id in relevant_ids
            ]
            
            # 6. å®¹é”™å¤„ç†ï¼ˆå¦‚æœéªŒè¯å¤±è´¥ï¼Œè¿”å›æ‰€æœ‰ç»“æœï¼‰
            if not relevant_ids:
                logger.warning("Validation returned no relevant IDs, returning all results")
                return tool_results, {"message": "éªŒè¯æœªè¯†åˆ«åˆ°ç›¸å…³ç»“æœï¼Œè¿”å›æ‰€æœ‰ç»“æœ"}
            
            logger.info(f"Validated {len(tool_results)} results, kept {len(relevant_items)} relevant items")
            return relevant_items, validation_message
        
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse validation JSON: {e}")
            return tool_results, {"message": "éªŒè¯ç»“æœè§£æå¤±è´¥ï¼Œè¿”å›æ‰€æœ‰ç»“æœ"}
        except Exception as e:
            logger.exception(f"Error in validate_and_filter_tool_results: {e}")
            return tool_results, {"message": f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}"}

    async def retrieve_session_memory(
        self,
        session_id: str,
        query: str
    ) -> List[ContextItem]:
        """
        ä»ä¼šè¯è®°å¿†æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            session_id: ä¼šè¯ID
            query: ç”¨æˆ·æŸ¥è¯¢ï¼Œç”¨äºæ£€ç´¢ç›¸å…³è®°å¿†
        
        Returns:
            æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡é¡¹åˆ—è¡¨
        """
        try:
            memory_tool = self.tools_executor.get_tool("session_memory")
            if not memory_tool:
                logger.debug("Session memory tool not available")
                return []
            
            # æ£€ç´¢ä¼šè¯è®°å¿†
            result = memory_tool.execute(
                action="retrieve",
                session_id=session_id,
                query=query,
                limit=10
            )
            
            if not result.get("success", False):
                return []
            
            # è½¬æ¢ä¸º ContextItem
            items = []
            memory_items = result.get("items", [])
            
            for i, memory_item in enumerate(memory_items):
                content = memory_item.get("content", "")
                content_type = memory_item.get("type", "general")
                
                context_item = ContextItem(
                    id=f"session_memory_{session_id}_{i}",
                    content=content,
                    source="session_memory",
                    metadata={
                        "content_type": content_type,
                        "timestamp": memory_item.get("timestamp", ""),
                        **memory_item.get("metadata", {})
                    },
                    relevance_score=0.95  # ä¼šè¯è®°å¿†ç›¸å…³æ€§å¾ˆé«˜
                )
                items.append(context_item)
            
            logger.info(f"Retrieved {len(items)} items from session memory")
            return items
            
        except Exception as e:
            logger.exception(f"Error retrieving session memory: {e}")
            return []

    async def store_to_session_memory(
        self,
        session_id: str,
        context: ContextCollection,
        query: str
    ):
        """
        å°†ä¸Šä¸‹æ–‡ä¸­çš„å…³é”®ä¿¡æ¯å­˜å‚¨åˆ°ä¼šè¯è®°å¿†
        
        Args:
            session_id: ä¼šè¯ID
            context: ä¸Šä¸‹æ–‡é›†åˆ
            query: ç”¨æˆ·æŸ¥è¯¢
        """
        try:
            memory_tool = self.tools_executor.get_tool("session_memory")
            if not memory_tool:
                logger.debug("Session memory tool not available")
                return
            
            # ä»ä¸Šä¸‹æ–‡ä¸­æå–å…³é”®ä¿¡æ¯
            # ä¼˜å…ˆæå–ç”¨æˆ·å¾…åŠäº‹é¡¹ä¸­çš„ä¿¡æ¯
            user_profile_items = [
                item for item in context.items
                if item.source == "user_profile" and item.metadata.get("context_type") == "task"
            ]
            
            stored_count = 0
            for item in user_profile_items:
                content = item.content.strip()
                if content and len(content) > 0:
                    # å­˜å‚¨åˆ°ä¼šè¯è®°å¿†
                    result = memory_tool.execute(
                        action="store",
                        session_id=session_id,
                        content=content,
                        content_type="task"
                    )
                    if result.get("success", False):
                        stored_count += 1
            
            if stored_count > 0:
                logger.info(f"Stored {stored_count} items to session memory")
            
        except Exception as e:
            logger.exception(f"Error storing to session memory: {e}")